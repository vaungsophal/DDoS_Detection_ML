{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "sZqR53AE8mA7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import loadtxt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from tqdm import tqdm\n",
    "from xgboost import plot_importance\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RJzIQYYh88a3",
    "outputId": "6bf10c09-0b6d-4eb1-e63c-41a85c5f0eb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Flow ID        Src IP  Src Port        Dst IP  Dst Port  \\\n",
      "0       1.921683e+29  1.921683e+09     38694  2.001752e+09      4444   \n",
      "1       1.921683e+29  1.921683e+09     38693  2.001752e+09      4444   \n",
      "2       1.921683e+29  2.001752e+09     33747  1.921683e+09      3632   \n",
      "3       1.921683e+29  2.001752e+09     38745  1.921683e+09      8180   \n",
      "4       1.921683e+29  2.001752e+09     37217  1.921683e+09      8180   \n",
      "...              ...           ...       ...           ...       ...   \n",
      "205162  1.851272e+29  1.921682e+10     36100  1.851272e+09       443   \n",
      "205163  1.921682e+28  1.921682e+10     53032  1.921682e+08        53   \n",
      "205164  1.921682e+28  1.921682e+10     39285  1.921682e+08        53   \n",
      "205165  1.921682e+28  1.921682e+10     49895  1.921682e+08        53   \n",
      "205166  1.921682e+28  1.921682e+10     33786  1.921682e+08        53   \n",
      "\n",
      "        Protocol     Timestamp  Flow Duration  Tot Fwd Pkts  Tot Bwd Pkts  \\\n",
      "0              6  1.012021e+09         269709             4             5   \n",
      "1              6  1.012021e+09         268599             2             3   \n",
      "2              6  1.012021e+09          22194             5             5   \n",
      "3              6  1.012020e+09           9556             4             4   \n",
      "4              6  1.012020e+09           8782             4             4   \n",
      "...          ...           ...            ...           ...           ...   \n",
      "205162         6  5.220202e+09           1895             0             2   \n",
      "205163        17  5.220202e+09           3842             1             3   \n",
      "205164        17  5.220202e+09           3731             1             3   \n",
      "205165        17  5.220202e+09          20591             0             2   \n",
      "205166        17  5.220202e+09           3039             1             3   \n",
      "\n",
      "        ...  Fwd Seg Size Min  Active Mean  Active Std  Active Max  \\\n",
      "0       ...                 0          0.0         0.0         0.0   \n",
      "1       ...                 0          0.0         0.0         0.0   \n",
      "2       ...                 0          0.0         0.0         0.0   \n",
      "3       ...                 0          0.0         0.0         0.0   \n",
      "4       ...                 0          0.0         0.0         0.0   \n",
      "...     ...               ...          ...         ...         ...   \n",
      "205162  ...                 0          0.0         0.0         0.0   \n",
      "205163  ...                 0          0.0         0.0         0.0   \n",
      "205164  ...                 0          0.0         0.0         0.0   \n",
      "205165  ...                 0          0.0         0.0         0.0   \n",
      "205166  ...                 0          0.0         0.0         0.0   \n",
      "\n",
      "        Active Min  Idle Mean  Idle Std  Idle Max  Idle Min   Label  \n",
      "0              0.0        0.0       0.0       0.0       0.0     U2R  \n",
      "1              0.0        0.0       0.0       0.0       0.0     U2R  \n",
      "2              0.0        0.0       0.0       0.0       0.0     U2R  \n",
      "3              0.0        0.0       0.0       0.0       0.0     BFA  \n",
      "4              0.0        0.0       0.0       0.0       0.0     BFA  \n",
      "...            ...        ...       ...       ...       ...     ...  \n",
      "205162         0.0        0.0       0.0       0.0       0.0  Normal  \n",
      "205163         0.0        0.0       0.0       0.0       0.0  Normal  \n",
      "205164         0.0        0.0       0.0       0.0       0.0  Normal  \n",
      "205165         0.0        0.0       0.0       0.0       0.0  Normal  \n",
      "205166         0.0        0.0       0.0       0.0       0.0  Normal  \n",
      "\n",
      "[205167 rows x 84 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import the dataset\n",
    "df = pd.concat(map(pd.read_csv, ['metasploitable-2.csv','Normal_data.csv']), ignore_index=True)\n",
    "df[\"Src IP\"] = [float(str(i).replace(\".\", \"\")) for i in df[\"Src IP\"]]\n",
    "df[\"Dst IP\"] = [float(str(i).replace(\".\", \"\")) for i in df[\"Dst IP\"]]\n",
    "df[\"Flow ID\"] = [float(str(i).replace(\".\", \"\").replace(\"-\", \"\")) for i in df[\"Flow ID\"]]\n",
    "df[\"Timestamp\"] = [float(str(i).replace(\"/\", \"\").replace(\":\", \"\").replace(\" \",\"\").replace(\"PM\",\"\")) for i in df[\"Timestamp\"]]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "VIazN91U_fK6"
   },
   "outputs": [],
   "source": [
    "# Splitting dataset into features and label\n",
    "X = df.drop('Label', axis=1)\n",
    "y = df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Urf9_UtK_qa3"
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into the training set and the test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Rfzwqzox_9qo"
   },
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 79
    },
    "id": "mZzAY-LrAsVI",
    "outputId": "1a3f214c-6c9e-4a58-e7b6-89ad4e11267f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=0)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear', random_state=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting SVM with the training set\n",
    "SVM = SVC(kernel='linear', random_state=0)\n",
    "SVM.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "uj7vUswMAtXm"
   },
   "outputs": [],
   "source": [
    "# Testing the model by classifying the test set\n",
    "y_pred = SVM.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "8WitqtZnAwKJ"
   },
   "outputs": [],
   "source": [
    "# Creating confusion matrix for evaluation\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cr = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "G0-fvedNCvUi"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import plot_importance\n",
    "from numpy import loadtxt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hZ0x8VCUC95k",
    "outputId": "cf4d9cb1-67a7-49a7-ce0b-ba9d430b6941"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "#run this if you want to upload the dataset from your google drive\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a6nQenJzDIE7",
    "outputId": "998acd6a-ee90-4bf2-ec79-97e10a91fcfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Flow ID        Src IP  Src Port        Dst IP  Dst Port  Protocol  \\\n",
      "0      1.921683e+29  1.921683e+09     38694  2.001752e+09      4444         6   \n",
      "1      1.921683e+29  1.921683e+09     38693  2.001752e+09      4444         6   \n",
      "2      1.921683e+29  2.001752e+09     33747  1.921683e+09      3632         6   \n",
      "3      1.921683e+29  2.001752e+09     38745  1.921683e+09      8180         6   \n",
      "4      1.921683e+29  2.001752e+09     37217  1.921683e+09      8180         6   \n",
      "...             ...           ...       ...           ...       ...       ...   \n",
      "68419  1.851272e+29  1.921682e+10     36100  1.851272e+09       443         6   \n",
      "68420  1.921682e+28  1.921682e+10     53032  1.921682e+08        53        17   \n",
      "68421  1.921682e+28  1.921682e+10     39285  1.921682e+08        53        17   \n",
      "68422  1.921682e+28  1.921682e+10     49895  1.921682e+08        53        17   \n",
      "68423  1.921682e+28  1.921682e+10     33786  1.921682e+08        53        17   \n",
      "\n",
      "          Timestamp  Flow Duration  Tot Fwd Pkts  Tot Bwd Pkts  ...  \\\n",
      "0      1.012021e+09         269709             4             5  ...   \n",
      "1      1.012021e+09         268599             2             3  ...   \n",
      "2      1.012021e+09          22194             5             5  ...   \n",
      "3      1.012020e+09           9556             4             4  ...   \n",
      "4      1.012020e+09           8782             4             4  ...   \n",
      "...             ...            ...           ...           ...  ...   \n",
      "68419  5.220202e+09           1895             0             2  ...   \n",
      "68420  5.220202e+09           3842             1             3  ...   \n",
      "68421  5.220202e+09           3731             1             3  ...   \n",
      "68422  5.220202e+09          20591             0             2  ...   \n",
      "68423  5.220202e+09           3039             1             3  ...   \n",
      "\n",
      "       Fwd Seg Size Min  Active Mean  Active Std  Active Max  Active Min  \\\n",
      "0                     0          0.0         0.0         0.0         0.0   \n",
      "1                     0          0.0         0.0         0.0         0.0   \n",
      "2                     0          0.0         0.0         0.0         0.0   \n",
      "3                     0          0.0         0.0         0.0         0.0   \n",
      "4                     0          0.0         0.0         0.0         0.0   \n",
      "...                 ...          ...         ...         ...         ...   \n",
      "68419                 0          0.0         0.0         0.0         0.0   \n",
      "68420                 0          0.0         0.0         0.0         0.0   \n",
      "68421                 0          0.0         0.0         0.0         0.0   \n",
      "68422                 0          0.0         0.0         0.0         0.0   \n",
      "68423                 0          0.0         0.0         0.0         0.0   \n",
      "\n",
      "       Idle Mean  Idle Std  Idle Max  Idle Min   Label  \n",
      "0            0.0       0.0       0.0       0.0     U2R  \n",
      "1            0.0       0.0       0.0       0.0     U2R  \n",
      "2            0.0       0.0       0.0       0.0     U2R  \n",
      "3            0.0       0.0       0.0       0.0     BFA  \n",
      "4            0.0       0.0       0.0       0.0     BFA  \n",
      "...          ...       ...       ...       ...     ...  \n",
      "68419        0.0       0.0       0.0       0.0  Normal  \n",
      "68420        0.0       0.0       0.0       0.0  Normal  \n",
      "68421        0.0       0.0       0.0       0.0  Normal  \n",
      "68422        0.0       0.0       0.0       0.0  Normal  \n",
      "68423        0.0       0.0       0.0       0.0  Normal  \n",
      "\n",
      "[205167 rows x 84 columns]\n"
     ]
    }
   ],
   "source": [
    "train= pd.concat(map(pd.read_csv, ['metasploitable-2.csv', 'Normal_data.csv']))\n",
    "train[\"Src IP\"] = [float(str(i).replace(\".\", \"\")) for i in train[\"Src IP\"]]\n",
    "train[\"Dst IP\"] = [float(str(i).replace(\".\", \"\")) for i in train[\"Dst IP\"]]\n",
    "train[\"Flow ID\"] = [float(str(i).replace(\".\", \"\").replace(\"-\", \"\")) for i in train[\"Flow ID\"]]\n",
    "train[\"Timestamp\"] = [float(str(i).replace(\"/\", \"\").replace(\":\", \"\").replace(\" \",\"\").replace(\"PM\",\"\")) for i in train[\"Timestamp\"]]\n",
    "print(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "NV3-Q_otDPWl"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "for f in train.columns:\n",
    "  if train[f].dtype=='object':\n",
    "    label = preprocessing.LabelEncoder()\n",
    "    label.fit(list(train[f].values))\n",
    "    train[f] = label.transform(list(train[f].values))\n",
    "train.fillna((-999), inplace=True)\n",
    "train=np.array(train)\n",
    "train = train.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8UyI2JHzDUFU",
    "outputId": "c9742119-344c-4a0b-8022-7628968c461c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  0             1        2             3       4     5   \\\n",
      "0       1.921683e+29  1.921683e+09  38694.0  2.001752e+09  4444.0   6.0   \n",
      "1       1.921683e+29  1.921683e+09  38693.0  2.001752e+09  4444.0   6.0   \n",
      "2       1.921683e+29  2.001752e+09  33747.0  1.921683e+09  3632.0   6.0   \n",
      "3       1.921683e+29  2.001752e+09  38745.0  1.921683e+09  8180.0   6.0   \n",
      "4       1.921683e+29  2.001752e+09  37217.0  1.921683e+09  8180.0   6.0   \n",
      "...              ...           ...      ...           ...     ...   ...   \n",
      "205162  1.851272e+29  1.921682e+10  36100.0  1.851272e+09   443.0   6.0   \n",
      "205163  1.921682e+28  1.921682e+10  53032.0  1.921682e+08    53.0  17.0   \n",
      "205164  1.921682e+28  1.921682e+10  39285.0  1.921682e+08    53.0  17.0   \n",
      "205165  1.921682e+28  1.921682e+10  49895.0  1.921682e+08    53.0  17.0   \n",
      "205166  1.921682e+28  1.921682e+10  33786.0  1.921682e+08    53.0  17.0   \n",
      "\n",
      "                  6         7    8    9   ...   74   75   76   77   78   79  \\\n",
      "0       1.012021e+09  269709.0  4.0  5.0  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1       1.012021e+09  268599.0  2.0  3.0  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "2       1.012021e+09   22194.0  5.0  5.0  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "3       1.012020e+09    9556.0  4.0  4.0  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "4       1.012020e+09    8782.0  4.0  4.0  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "...              ...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "205162  5.220202e+09    1895.0  0.0  2.0  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "205163  5.220202e+09    3842.0  1.0  3.0  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "205164  5.220202e+09    3731.0  1.0  3.0  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "205165  5.220202e+09   20591.0  0.0  2.0  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "205166  5.220202e+09    3039.0  1.0  3.0  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "         80   81   82   83  \n",
      "0       0.0  0.0  0.0  5.0  \n",
      "1       0.0  0.0  0.0  5.0  \n",
      "2       0.0  0.0  0.0  5.0  \n",
      "3       0.0  0.0  0.0  0.0  \n",
      "4       0.0  0.0  0.0  0.0  \n",
      "...     ...  ...  ...  ...  \n",
      "205162  0.0  0.0  0.0  3.0  \n",
      "205163  0.0  0.0  0.0  3.0  \n",
      "205164  0.0  0.0  0.0  3.0  \n",
      "205165  0.0  0.0  0.0  3.0  \n",
      "205166  0.0  0.0  0.0  3.0  \n",
      "\n",
      "[205167 rows x 84 columns]\n"
     ]
    }
   ],
   "source": [
    "train = pd.DataFrame(train)\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "yM_7vqcnDdV1"
   },
   "outputs": [],
   "source": [
    "X = train.drop(train.columns[[81]], axis=1)\n",
    "y=train[train.columns[[81]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "K6s0CwCYDfjg"
   },
   "outputs": [],
   "source": [
    "# split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "uC0E0znHDhUa"
   },
   "outputs": [],
   "source": [
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "X_test = StandardScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 135
    },
    "id": "j884E157DngW",
    "outputId": "525dbe96-0266-42c3-f6f5-b28ae49095f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GaussianNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.GaussianNB.html\">?<span>Documentation for GaussianNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GaussianNB()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB=GaussianNB()\n",
    "NB.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "WQYuakayDs0u"
   },
   "outputs": [],
   "source": [
    "y_pred = NB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kysPtgBXDs-7",
    "outputId": "de786c56-dcbe-480a-de8b-3676aaac1f4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8401975597472016\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy:\",accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sEFErwraDvRN",
    "outputId": "50629b8c-a5f8-47eb-f210-46f8236fcd44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-acore: 0.8401975597472016\n"
     ]
    }
   ],
   "source": [
    "f1score=f1_score(y_test, y_pred, average='micro')\n",
    "print(\"f1-acore:\",f1score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j8iK9_VGD1w0",
    "outputId": "0b14f215-a8f8-4388-b92c-824aeb9ab2d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [[51676     0     0 ...     0     0     0]\n",
      " [    0     0     0 ...     0     0     0]\n",
      " [    0     0     0 ...     0     0     0]\n",
      " ...\n",
      " [    0     0     0 ...     0     0     0]\n",
      " [    0     0     0 ...     0     0     0]\n",
      " [    0     0     0 ...     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "cm=confusion_matrix(y_test, y_pred)\n",
    "print(\"confusion matrix:\",cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D9Kta-PrD3ga",
    "outputId": "8123982f-dd28-44e7-bd0a-1a516e596ec0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00     52045\n",
      "   5000001.0       0.00      0.00      0.00         1\n",
      "   5000015.0       0.00      0.00      0.00         1\n",
      "   5000058.0       0.00      0.00      0.00         1\n",
      "   5000120.0       0.00      0.00      0.00         1\n",
      "   5000133.0       0.00      0.00      0.00         1\n",
      "   5000140.0       0.00      0.00      0.00         1\n",
      "   5000150.0       0.00      0.00      0.00         1\n",
      "   5000154.0       0.00      0.00      0.00         1\n",
      "   5000157.0       0.00      0.00      0.00         1\n",
      "   5000167.0       0.00      0.00      0.00         1\n",
      "   5000183.0       0.00      0.00      0.00         1\n",
      "   5000191.0       0.00      0.00      0.00         1\n",
      "   5000251.0       0.00      0.00      0.00         1\n",
      "   5000254.0       0.00      0.00      0.00         1\n",
      "   5000259.0       0.00      0.00      0.00         1\n",
      "   5000265.0       0.00      0.00      0.00         1\n",
      "   5000267.0       0.00      0.00      0.00         1\n",
      "   5000270.0       0.00      0.00      0.00         1\n",
      "   5000288.0       0.00      0.00      0.00         1\n",
      "   5000304.0       0.00      0.00      0.00         1\n",
      "   5000311.0       0.00      0.00      0.00         1\n",
      "   5000332.0       0.00      0.00      0.00         1\n",
      "   5000337.0       0.00      0.00      0.00         1\n",
      "   5000369.0       0.00      0.00      0.00         1\n",
      "   5000400.0       0.00      0.00      0.00         1\n",
      "   5000401.0       0.00      0.00      0.00         1\n",
      "   5000408.0       0.00      0.00      0.00         1\n",
      "   5000413.0       0.00      0.00      0.00         1\n",
      "   5000416.0       0.00      0.00      0.00         1\n",
      "   5000440.0       0.00      0.00      0.00         1\n",
      "   5000457.0       0.00      0.00      0.00         1\n",
      "   5000480.0       0.00      0.00      0.00         1\n",
      "   5000512.0       0.00      0.00      0.00         1\n",
      "   5000518.0       0.00      0.00      0.00         1\n",
      "   5000539.0       0.00      0.00      0.00         1\n",
      "   5000547.0       0.00      0.00      0.00         1\n",
      "   5000587.0       0.00      0.00      0.00         1\n",
      "   5000589.0       0.00      0.00      0.00         1\n",
      "   5000601.0       0.00      0.00      0.00         1\n",
      "   5000614.0       0.00      0.00      0.00         1\n",
      "   5000617.0       0.00      0.00      0.00         1\n",
      "   5000621.0       0.00      0.00      0.00         1\n",
      "   5000622.0       0.00      0.00      0.00         1\n",
      "   5000673.0       0.00      0.00      0.00         1\n",
      "   5000678.0       0.00      0.00      0.00         1\n",
      "   5000685.0       0.00      0.00      0.00         1\n",
      "   5000694.0       0.00      0.00      0.00         1\n",
      "   5000700.0       0.00      0.00      0.00         1\n",
      "   5000709.0       0.00      0.00      0.00         1\n",
      "   5000711.0       0.00      0.00      0.00         1\n",
      "   5000720.0       0.00      0.00      0.00         1\n",
      "   5000732.0       0.00      0.00      0.00         1\n",
      "   5000743.0       0.00      0.00      0.00         1\n",
      "   5000772.0       0.00      0.00      0.00         1\n",
      "   5000777.0       0.00      0.00      0.00         1\n",
      "   5000780.0       0.00      0.00      0.00         2\n",
      "   5000793.0       0.00      0.00      0.00         1\n",
      "   5000794.0       0.00      0.00      0.00         1\n",
      "   5000797.0       0.00      0.00      0.00         1\n",
      "   5000819.0       0.00      0.00      0.00         1\n",
      "   5000862.0       0.00      0.00      0.00         1\n",
      "   5000865.0       0.00      0.00      0.00         1\n",
      "   5000866.0       0.00      0.00      0.00         1\n",
      "   5000877.0       0.00      0.00      0.00         1\n",
      "   5000881.0       0.00      0.00      0.00         1\n",
      "   5000882.0       0.00      0.00      0.00         1\n",
      "   5000884.0       0.00      0.00      0.00         1\n",
      "   5000885.0       0.00      0.00      0.00         1\n",
      "   5000908.0       0.00      0.00      0.00         1\n",
      "   5000926.0       0.00      0.00      0.00         1\n",
      "   5000935.0       0.00      0.00      0.00         1\n",
      "   5000946.0       0.00      0.00      0.00         1\n",
      "   5000954.0       0.00      0.00      0.00         1\n",
      "   5000968.0       0.00      0.00      0.00         1\n",
      "   5000973.0       0.00      0.00      0.00         1\n",
      "   5000976.0       0.00      0.00      0.00         1\n",
      "   5001013.0       0.00      0.00      0.00         1\n",
      "   5001034.0       0.00      0.00      0.00         1\n",
      "   5001039.0       0.00      0.00      0.00         1\n",
      "   5001066.0       0.00      0.00      0.00         1\n",
      "   5001069.0       0.00      0.00      0.00         1\n",
      "   5001105.0       0.00      0.00      0.00         1\n",
      "   5001106.0       0.00      0.00      0.00         1\n",
      "   5001114.0       0.00      0.00      0.00         1\n",
      "   5001133.0       0.00      0.00      0.00         1\n",
      "   5001140.0       0.00      0.00      0.00         1\n",
      "   5001162.0       0.00      0.00      0.00         1\n",
      "   5001178.0       0.00      0.00      0.00         1\n",
      "   5001183.0       0.00      0.00      0.00         1\n",
      "   5001196.0       0.00      0.00      0.00         1\n",
      "   5001200.0       0.00      0.00      0.00         1\n",
      "   5001218.0       0.00      0.00      0.00         1\n",
      "   5001248.0       0.00      0.00      0.00         1\n",
      "   5001255.0       0.00      0.00      0.00         1\n",
      "   5001260.0       0.00      0.00      0.00         1\n",
      "   5001266.0       0.00      0.00      0.00         1\n",
      "   5001293.0       0.00      0.00      0.00         1\n",
      "   5001312.0       0.00      0.00      0.00         1\n",
      "   5001315.0       0.00      0.00      0.00         1\n",
      "   5001363.0       0.00      0.00      0.00         1\n",
      "   5001385.0       0.00      0.00      0.00         1\n",
      "   5001403.0       0.00      0.00      0.00         1\n",
      "   5001411.0       0.00      0.00      0.00         1\n",
      "   5001455.0       0.00      0.00      0.00         1\n",
      "   5001461.0       0.00      0.00      0.00         1\n",
      "   5001474.0       0.00      0.00      0.00         1\n",
      "   5001489.0       0.00      0.00      0.00         1\n",
      "   5001539.0       0.00      0.00      0.00         1\n",
      "   5001557.0       0.00      0.00      0.00         1\n",
      "   5001567.0       0.00      0.00      0.00         1\n",
      "   5001583.0       0.00      0.00      0.00         1\n",
      "   5001586.0       0.00      0.00      0.00         2\n",
      "   5001588.0       0.00      0.00      0.00         1\n",
      "   5001601.0       0.00      0.00      0.00         1\n",
      "   5001603.0       0.00      0.00      0.00         1\n",
      "   5001604.0       0.00      0.00      0.00         1\n",
      "   5001612.0       0.00      0.00      0.00         1\n",
      "   5001621.0       0.00      0.00      0.00         1\n",
      "   5001622.0       0.00      0.00      0.00         1\n",
      "   5001658.0       0.00      0.00      0.00         1\n",
      "   5001673.0       0.00      0.00      0.00         1\n",
      "   5001675.0       0.00      0.00      0.00         1\n",
      "   5001708.0       0.00      0.00      0.00         1\n",
      "   5001710.0       0.00      0.00      0.00         1\n",
      "   5001754.0       0.00      0.00      0.00         1\n",
      "   5001806.0       0.00      0.00      0.00         1\n",
      "   5001813.0       0.00      0.00      0.00         1\n",
      "   5001843.0       0.00      0.00      0.00         1\n",
      "   5001870.0       0.00      0.00      0.00         1\n",
      "   5001871.0       0.00      0.00      0.00         2\n",
      "   5001933.0       0.00      0.00      0.00         1\n",
      "   5001934.0       0.00      0.00      0.00         1\n",
      "   5001947.0       0.00      0.00      0.00         1\n",
      "   5001983.0       0.00      0.00      0.00         1\n",
      "   5002001.0       0.00      0.00      0.00         1\n",
      "   5002003.0       0.00      0.00      0.00         1\n",
      "   5002012.0       0.00      0.00      0.00         1\n",
      "   5002026.0       0.00      0.00      0.00         1\n",
      "   5002030.0       0.00      0.00      0.00         1\n",
      "   5002046.0       0.00      0.00      0.00         1\n",
      "   5002081.0       0.00      0.00      0.00         1\n",
      "   5002085.0       0.00      0.00      0.00         1\n",
      "   5002110.0       0.00      0.00      0.00         1\n",
      "   5002128.0       0.00      0.00      0.00         1\n",
      "   5002153.0       0.00      0.00      0.00         1\n",
      "   5002208.0       0.00      0.00      0.00         1\n",
      "   5002245.0       0.00      0.00      0.00         1\n",
      "   5002276.0       0.00      0.00      0.00         1\n",
      "   5002285.0       0.00      0.00      0.00         1\n",
      "   5002300.0       0.00      0.00      0.00         1\n",
      "   5002326.0       0.00      0.00      0.00         1\n",
      "   5002365.0       0.00      0.00      0.00         1\n",
      "   5002371.0       0.00      0.00      0.00         1\n",
      "   5002381.0       0.00      0.00      0.00         1\n",
      "   5002383.0       0.00      0.00      0.00         1\n",
      "   5002388.0       0.00      0.00      0.00         1\n",
      "   5002397.0       0.00      0.00      0.00         1\n",
      "   5002409.0       0.00      0.00      0.00         1\n",
      "   5002414.0       0.00      0.00      0.00         1\n",
      "   5002433.0       0.00      0.00      0.00         1\n",
      "   5002440.0       0.00      0.00      0.00         1\n",
      "   5002442.0       0.00      0.00      0.00         1\n",
      "   5002444.0       0.00      0.00      0.00         1\n",
      "   5002506.0       0.00      0.00      0.00         1\n",
      "   5002534.0       0.00      0.00      0.00         1\n",
      "   5002560.0       0.00      0.00      0.00         1\n",
      "   5002569.0       0.00      0.00      0.00         1\n",
      "   5002597.0       0.00      0.00      0.00         1\n",
      "   5002606.0       0.00      0.00      0.00         1\n",
      "   5002663.0       0.00      0.00      0.00         1\n",
      "   5002682.0       0.00      0.00      0.00         1\n",
      "   5002686.0       0.00      0.00      0.00         1\n",
      "   5002726.0       0.00      0.00      0.00         1\n",
      "   5002732.0       0.00      0.00      0.00         1\n",
      "   5002753.0       0.00      0.00      0.00         1\n",
      "   5002754.0       0.00      0.00      0.00         1\n",
      "   5002847.0       0.00      0.00      0.00         1\n",
      "   5002914.0       0.00      0.00      0.00         1\n",
      "   5002964.0       0.00      0.00      0.00         1\n",
      "   5002998.0       0.00      0.00      0.00         1\n",
      "   5003020.0       0.00      0.00      0.00         1\n",
      "   5003033.0       0.00      0.00      0.00         1\n",
      "   5003070.0       0.00      0.00      0.00         1\n",
      "   5003098.0       0.00      0.00      0.00         1\n",
      "   5003161.0       0.00      0.00      0.00         1\n",
      "   5003229.0       0.00      0.00      0.00         1\n",
      "   5003269.0       0.00      0.00      0.00         1\n",
      "   5003335.0       0.00      0.00      0.00         1\n",
      "   5003368.0       0.00      0.00      0.00         1\n",
      "   5003375.0       0.00      0.00      0.00         1\n",
      "   5003429.0       0.00      0.00      0.00         1\n",
      "   5003545.0       0.00      0.00      0.00         1\n",
      "   5003589.0       0.00      0.00      0.00         1\n",
      "   5003599.0       0.00      0.00      0.00         1\n",
      "   5003644.0       0.00      0.00      0.00         1\n",
      "   5003658.0       0.00      0.00      0.00         1\n",
      "   5003689.0       0.00      0.00      0.00         1\n",
      "   5003826.0       0.00      0.00      0.00         1\n",
      "   5003989.0       0.00      0.00      0.00         1\n",
      "   5004172.0       0.00      0.00      0.00         1\n",
      "   5004276.0       0.00      0.00      0.00         1\n",
      "   5004344.0       0.00      0.00      0.00         1\n",
      "   5004865.0       0.00      0.00      0.00         1\n",
      "   5005718.0       0.00      0.00      0.00         1\n",
      "   5006377.0       0.00      0.00      0.00         1\n",
      "   5006922.0       0.00      0.00      0.00         1\n",
      "   5007046.0       0.00      0.00      0.00         1\n",
      "   5007563.0       0.00      0.00      0.00         1\n",
      "   5008985.0       0.00      0.00      0.00         1\n",
      "   5009174.0       0.00      0.00      0.00         1\n",
      "   5009777.0       0.00      0.00      0.00         1\n",
      "   5010385.0       0.00      0.00      0.00         1\n",
      "   5010425.0       0.00      0.00      0.00         1\n",
      "   5010476.0       0.00      0.00      0.00         1\n",
      "   5010730.0       0.00      0.00      0.00         1\n",
      "   5010800.0       0.00      0.00      0.00         1\n",
      "   5011020.0       0.00      0.00      0.00         1\n",
      "   5011428.0       0.00      0.00      0.00         1\n",
      "   5011964.0       0.00      0.00      0.00         1\n",
      "   5014439.0       0.00      0.00      0.00         1\n",
      "   5015964.0       0.00      0.00      0.00         1\n",
      "   5017365.0       0.00      0.00      0.00         1\n",
      "   5019777.0       0.00      0.00      0.00         1\n",
      "   5026487.0       0.00      0.00      0.00         1\n",
      "   5029126.0       0.00      0.00      0.00         1\n",
      "   5036149.0       0.00      0.00      0.00         1\n",
      "   5038025.0       0.00      0.00      0.00         1\n",
      "   5040965.0       0.00      0.00      0.00         1\n",
      "   5042270.0       0.00      0.00      0.00         1\n",
      "   5048244.0       0.00      0.00      0.00         1\n",
      "   5048488.0       0.00      0.00      0.00         1\n",
      "   5048718.0       0.00      0.00      0.00         1\n",
      "   5056473.0       0.00      0.00      0.00         1\n",
      "   5058527.0       0.00      0.00      0.00         1\n",
      "   5059322.0       0.00      0.00      0.00         1\n",
      "   5060876.0       0.00      0.00      0.00         1\n",
      "   5064798.0       0.00      0.00      0.00         1\n",
      "   5066034.0       0.00      0.00      0.00         1\n",
      "   5067551.0       0.00      0.00      0.00         1\n",
      "   5074763.0       0.00      0.00      0.00         1\n",
      "   5077497.0       0.00      0.00      0.00         1\n",
      "   5078622.0       0.00      0.00      0.00         1\n",
      "   5079853.0       0.00      0.00      0.00         1\n",
      "   5082600.0       0.00      0.00      0.00         1\n",
      "   5082923.0       0.00      0.00      0.00         1\n",
      "   5085984.0       0.00      0.00      0.00         1\n",
      "   5088455.0       0.00      0.00      0.00         1\n",
      "   5089451.0       0.00      0.00      0.00         1\n",
      "   5090635.0       0.00      0.00      0.00         1\n",
      "   5092538.0       0.00      0.00      0.00         1\n",
      "   5093936.0       0.00      0.00      0.00         1\n",
      "   5094271.0       0.00      0.00      0.00         1\n",
      "   5094456.0       0.00      0.00      0.00         1\n",
      "   5098477.0       0.00      0.00      0.00         1\n",
      "   5098810.0       0.00      0.00      0.00         1\n",
      "   5100094.0       0.00      0.00      0.00         1\n",
      "   5105129.0       0.00      0.00      0.00         1\n",
      "   5111620.0       0.00      0.00      0.00         1\n",
      "   5117443.0       0.00      0.00      0.00         1\n",
      "   5120555.0       0.00      0.00      0.00         1\n",
      "   5120903.0       0.00      0.00      0.00         1\n",
      "   5122202.0       0.00      0.00      0.00         1\n",
      "   5123290.0       0.00      0.00      0.00         1\n",
      "   5123711.0       0.00      0.00      0.00         1\n",
      "   5128398.0       0.00      0.00      0.00         1\n",
      "   5129377.0       0.00      0.00      0.00         1\n",
      "   5130325.0       0.00      0.00      0.00         1\n",
      "   5132397.0       0.00      0.00      0.00         1\n",
      "   5134442.0       0.00      0.00      0.00         1\n",
      "   5140027.0       0.00      0.00      0.00         1\n",
      "   5141202.0       0.00      0.00      0.00         1\n",
      "   5141505.0       0.00      0.00      0.00         1\n",
      "   5143704.0       0.00      0.00      0.00         1\n",
      "   5143925.0       0.00      0.00      0.00         1\n",
      "   5147167.0       0.00      0.00      0.00         1\n",
      "   5150230.0       0.00      0.00      0.00         1\n",
      "   5151494.0       0.00      0.00      0.00         1\n",
      "   5155958.0       0.00      0.00      0.00         1\n",
      "   5156916.0       0.00      0.00      0.00         1\n",
      "   5158581.0       0.00      0.00      0.00         1\n",
      "   5158608.0       0.00      0.00      0.00         1\n",
      "   5159890.0       0.00      0.00      0.00         1\n",
      "   5162750.0       0.00      0.00      0.00         1\n",
      "   5162894.0       0.00      0.00      0.00         1\n",
      "   5165144.0       0.00      0.00      0.00         1\n",
      "   5165455.0       0.00      0.00      0.00         1\n",
      "   5167657.0       0.00      0.00      0.00         1\n",
      "   5167998.0       0.00      0.00      0.00         1\n",
      "   5168410.0       0.00      0.00      0.00         1\n",
      "   5169324.0       0.00      0.00      0.00         1\n",
      "   5176432.0       0.00      0.00      0.00         1\n",
      "   5177578.0       0.00      0.00      0.00         1\n",
      "   5179005.0       0.00      0.00      0.00         1\n",
      "   5181310.0       0.00      0.00      0.00         1\n",
      "   5182094.0       0.00      0.00      0.00         1\n",
      "   5188320.0       0.00      0.00      0.00         1\n",
      "   5188969.0       0.00      0.00      0.00         1\n",
      "   5189056.0       0.00      0.00      0.00         1\n",
      "   5193426.0       0.00      0.00      0.00         1\n",
      "   5195378.0       0.00      0.00      0.00         1\n",
      "   5197971.0       0.00      0.00      0.00         1\n",
      "   5198766.0       0.00      0.00      0.00         1\n",
      "   5200274.0       0.00      0.00      0.00         1\n",
      "   5201002.0       0.00      0.00      0.00         1\n",
      "   5202196.0       0.00      0.00      0.00         1\n",
      "   5203177.0       0.00      0.00      0.00         1\n",
      "   5203959.0       0.00      0.00      0.00         1\n",
      "   5206679.0       0.00      0.00      0.00         1\n",
      "   5208223.0       0.00      0.00      0.00         1\n",
      "   5209734.0       0.00      0.00      0.00         1\n",
      "   5210438.0       0.00      0.00      0.00         1\n",
      "   5211875.0       0.00      0.00      0.00         1\n",
      "   5215541.0       0.00      0.00      0.00         1\n",
      "   5216103.0       0.00      0.00      0.00         1\n",
      "   5217280.0       0.00      0.00      0.00         1\n",
      "   5218485.0       0.00      0.00      0.00         1\n",
      "   5222661.0       0.00      0.00      0.00         1\n",
      "   5223706.0       0.00      0.00      0.00         1\n",
      "   5224291.0       0.00      0.00      0.00         1\n",
      "   5226923.0       0.00      0.00      0.00         1\n",
      "   5228001.0       0.00      0.00      0.00         1\n",
      "   5234843.0       0.00      0.00      0.00         1\n",
      "   5240602.0       0.00      0.00      0.00         1\n",
      "   5241831.0       0.00      0.00      0.00         1\n",
      "   5242088.0       0.00      0.00      0.00         1\n",
      "   5247387.0       0.00      0.00      0.00         1\n",
      "   5248566.0       0.00      0.00      0.00         1\n",
      "   5248922.0       0.00      0.00      0.00         1\n",
      "   5252111.0       0.00      0.00      0.00         1\n",
      "   5256068.0       0.00      0.00      0.00         1\n",
      "   5256811.0       0.00      0.00      0.00         1\n",
      "   5258202.0       0.00      0.00      0.00         1\n",
      "   5261390.0       0.00      0.00      0.00         1\n",
      "   5263093.0       0.00      0.00      0.00         1\n",
      "   5266028.0       0.00      0.00      0.00         1\n",
      "   5269596.0       0.00      0.00      0.00         1\n",
      "   5269815.0       0.00      0.00      0.00         1\n",
      "   5270179.0       0.00      0.00      0.00         1\n",
      "   5271013.0       0.00      0.00      0.00         1\n",
      "   5272664.0       0.00      0.00      0.00         1\n",
      "   5273084.0       0.00      0.00      0.00         1\n",
      "   5273395.0       0.00      0.00      0.00         1\n",
      "   5274563.0       0.00      0.00      0.00         1\n",
      "   5276583.0       0.00      0.00      0.00         1\n",
      "   5277027.0       0.00      0.00      0.00         1\n",
      "   5277335.0       0.00      0.00      0.00         1\n",
      "   5278168.0       0.00      0.00      0.00         1\n",
      "   5280280.0       0.00      0.00      0.00         1\n",
      "   5280954.0       0.00      0.00      0.00         1\n",
      "   5282403.0       0.00      0.00      0.00         1\n",
      "   5284954.0       0.00      0.00      0.00         1\n",
      "   5291901.0       0.00      0.00      0.00         1\n",
      "   5292094.0       0.00      0.00      0.00         1\n",
      "   5293927.0       0.00      0.00      0.00         1\n",
      "   5294585.0       0.00      0.00      0.00         1\n",
      "   5294903.0       0.00      0.00      0.00         1\n",
      "   5296603.0       0.00      0.00      0.00         1\n",
      "   5297745.0       0.00      0.00      0.00         1\n",
      "   5300697.0       0.00      0.00      0.00         1\n",
      "   5307674.0       0.00      0.00      0.00         1\n",
      "   5308739.0       0.00      0.00      0.00         1\n",
      "   5310242.0       0.00      0.00      0.00         1\n",
      "   5311272.0       0.00      0.00      0.00         1\n",
      "   5311763.0       0.00      0.00      0.00         1\n",
      "   5312082.0       0.00      0.00      0.00         1\n",
      "   5313603.0       0.00      0.00      0.00         1\n",
      "   5315380.0       0.00      0.00      0.00         1\n",
      "   5319612.0       0.00      0.00      0.00         1\n",
      "   5319965.0       0.00      0.00      0.00         1\n",
      "   5320837.0       0.00      0.00      0.00         1\n",
      "   5320875.0       0.00      0.00      0.00         1\n",
      "   5325414.0       0.00      0.00      0.00         1\n",
      "   5329604.0       0.00      0.00      0.00         1\n",
      "   5329890.0       0.00      0.00      0.00         1\n",
      "   5332489.0       0.00      0.00      0.00         1\n",
      "   5333074.0       0.00      0.00      0.00         1\n",
      "   5333895.0       0.00      0.00      0.00         1\n",
      "   5334141.0       0.00      0.00      0.00         1\n",
      "   5334481.0       0.00      0.00      0.00         1\n",
      "   5335088.0       0.00      0.00      0.00         1\n",
      "   5337178.0       0.00      0.00      0.00         1\n",
      "   5337711.0       0.00      0.00      0.00         1\n",
      "   5338811.0       0.00      0.00      0.00         1\n",
      "   5340195.0       0.00      0.00      0.00         1\n",
      "   5347330.0       0.00      0.00      0.00         1\n",
      "   5352665.0       0.00      0.00      0.00         1\n",
      "   5353459.0       0.00      0.00      0.00         1\n",
      "   5358337.0       0.00      0.00      0.00         1\n",
      "   5366498.0       0.00      0.00      0.00         1\n",
      "   5368896.0       0.00      0.00      0.00         1\n",
      "   5373013.0       0.00      0.00      0.00         1\n",
      "   5374997.0       0.00      0.00      0.00         1\n",
      "   5375356.0       0.00      0.00      0.00         1\n",
      "   5376793.0       0.00      0.00      0.00         1\n",
      "   5380835.0       0.00      0.00      0.00         1\n",
      "   5381518.0       0.00      0.00      0.00         1\n",
      "   5383248.0       0.00      0.00      0.00         1\n",
      "   5383454.0       0.00      0.00      0.00         1\n",
      "   5384694.0       0.00      0.00      0.00         1\n",
      "   5390246.0       0.00      0.00      0.00         1\n",
      "   5391335.0       0.00      0.00      0.00         1\n",
      "   5399104.0       0.00      0.00      0.00         1\n",
      "   5399159.0       0.00      0.00      0.00         1\n",
      "   5401161.0       0.00      0.00      0.00         1\n",
      "   5404781.0       0.00      0.00      0.00         1\n",
      "   5412571.0       0.00      0.00      0.00         1\n",
      "   5414389.0       0.00      0.00      0.00         1\n",
      "   5420067.0       0.00      0.00      0.00         1\n",
      "   5420215.0       0.00      0.00      0.00         1\n",
      "   5421582.0       0.00      0.00      0.00         1\n",
      "   5421812.0       0.00      0.00      0.00         1\n",
      "   5425650.0       0.00      0.00      0.00         1\n",
      "   5426271.0       0.00      0.00      0.00         1\n",
      "   5427664.0       0.00      0.00      0.00         1\n",
      "   5428062.0       0.00      0.00      0.00         1\n",
      "   5428914.0       0.00      0.00      0.00         1\n",
      "   5431998.0       0.00      0.00      0.00         1\n",
      "   5441031.0       0.00      0.00      0.00         1\n",
      "   5447493.0       0.00      0.00      0.00         1\n",
      "   5451679.0       0.00      0.00      0.00         1\n",
      "   5454504.0       0.00      0.00      0.00         1\n",
      "   5456507.0       0.00      0.00      0.00         1\n",
      "   5462711.0       0.00      0.00      0.00         1\n",
      "   5474571.0       0.00      0.00      0.00         1\n",
      "   5479086.0       0.00      0.00      0.00         1\n",
      "   5479776.0       0.00      0.00      0.00         1\n",
      "   5485664.0       0.00      0.00      0.00         1\n",
      "   5488599.0       0.00      0.00      0.00         1\n",
      "   5490009.0       0.00      0.00      0.00         1\n",
      "   5492043.0       0.00      0.00      0.00         1\n",
      "   5493625.0       0.00      0.00      0.00         1\n",
      "   5496295.0       0.00      0.00      0.00         1\n",
      "   5505703.0       0.00      0.00      0.00         1\n",
      "   5507672.0       0.00      0.00      0.00         1\n",
      "   5508990.0       0.00      0.00      0.00         1\n",
      "   5512076.0       0.00      0.00      0.00         1\n",
      "   5513783.0       0.00      0.00      0.00         1\n",
      "   5516209.0       0.00      0.00      0.00         1\n",
      "   5520953.0       0.00      0.00      0.00         1\n",
      "   5523619.0       0.00      0.00      0.00         1\n",
      "   5523910.0       0.00      0.00      0.00         1\n",
      "   5531729.0       0.00      0.00      0.00         1\n",
      "   5534394.0       0.00      0.00      0.00         1\n",
      "   5536106.0       0.00      0.00      0.00         1\n",
      "   5542070.0       0.00      0.00      0.00         1\n",
      "   5543669.0       0.00      0.00      0.00         1\n",
      "   5545236.0       0.00      0.00      0.00         1\n",
      "   5545561.0       0.00      0.00      0.00         1\n",
      "   5547301.0       0.00      0.00      0.00         1\n",
      "   5547414.0       0.00      0.00      0.00         1\n",
      "   5547587.0       0.00      0.00      0.00         1\n",
      "   5549628.0       0.00      0.00      0.00         1\n",
      "   5550877.0       0.00      0.00      0.00         1\n",
      "   5554437.0       0.00      0.00      0.00         1\n",
      "   5555742.0       0.00      0.00      0.00         1\n",
      "   5556911.0       0.00      0.00      0.00         1\n",
      "   5558252.0       0.00      0.00      0.00         1\n",
      "   5560036.0       0.00      0.00      0.00         1\n",
      "   5564569.0       0.00      0.00      0.00         1\n",
      "   5566151.0       0.00      0.00      0.00         1\n",
      "   5570313.0       0.00      0.00      0.00         1\n",
      "   5570742.0       0.00      0.00      0.00         1\n",
      "   5570825.0       0.00      0.00      0.00         1\n",
      "   5576167.0       0.00      0.00      0.00         1\n",
      "   5577873.0       0.00      0.00      0.00         1\n",
      "   5580126.0       0.00      0.00      0.00         1\n",
      "   5582711.0       0.00      0.00      0.00         1\n",
      "   5587379.0       0.00      0.00      0.00         1\n",
      "   5593088.0       0.00      0.00      0.00         1\n",
      "   5593196.0       0.00      0.00      0.00         1\n",
      "   5593898.0       0.00      0.00      0.00         1\n",
      "   5598936.0       0.00      0.00      0.00         1\n",
      "   5600773.0       0.00      0.00      0.00         1\n",
      "   5604848.0       0.00      0.00      0.00         1\n",
      "   5607907.0       0.00      0.00      0.00         1\n",
      "   5610413.0       0.00      0.00      0.00         1\n",
      "   5610507.0       0.00      0.00      0.00         1\n",
      "   5611771.0       0.00      0.00      0.00         1\n",
      "   5613689.0       0.00      0.00      0.00         1\n",
      "   5615622.0       0.00      0.00      0.00         1\n",
      "   5619488.0       0.00      0.00      0.00         1\n",
      "   5626352.0       0.00      0.00      0.00         1\n",
      "   5628724.0       0.00      0.00      0.00         1\n",
      "   5631011.0       0.00      0.00      0.00         1\n",
      "   5631310.0       0.00      0.00      0.00         1\n",
      "   5632385.0       0.00      0.00      0.00         1\n",
      "   5644286.0       0.00      0.00      0.00         1\n",
      "   5647149.0       0.00      0.00      0.00         1\n",
      "   5653714.0       0.00      0.00      0.00         1\n",
      "   5655399.0       0.00      0.00      0.00         1\n",
      "   5658801.0       0.00      0.00      0.00         1\n",
      "   5659163.0       0.00      0.00      0.00         1\n",
      "   5659245.0       0.00      0.00      0.00         1\n",
      "   5659946.0       0.00      0.00      0.00         1\n",
      "   5659969.0       0.00      0.00      0.00         1\n",
      "   5661561.0       0.00      0.00      0.00         1\n",
      "   5669335.0       0.00      0.00      0.00         1\n",
      "   5671581.0       0.00      0.00      0.00         1\n",
      "   5675145.0       0.00      0.00      0.00         1\n",
      "   5677818.0       0.00      0.00      0.00         1\n",
      "   5679065.0       0.00      0.00      0.00         1\n",
      "   5679420.0       0.00      0.00      0.00         1\n",
      "   5686007.0       0.00      0.00      0.00         1\n",
      "   5693084.0       0.00      0.00      0.00         1\n",
      "   5694639.0       0.00      0.00      0.00         1\n",
      "   5697563.0       0.00      0.00      0.00         1\n",
      "   5698336.0       0.00      0.00      0.00         1\n",
      "   5698604.0       0.00      0.00      0.00         1\n",
      "   5703182.0       0.00      0.00      0.00         1\n",
      "   5705680.0       0.00      0.00      0.00         1\n",
      "   5708176.0       0.00      0.00      0.00         1\n",
      "   5718796.0       0.00      0.00      0.00         1\n",
      "   5720997.0       0.00      0.00      0.00         1\n",
      "   5723185.0       0.00      0.00      0.00         1\n",
      "   5725078.0       0.00      0.00      0.00         1\n",
      "   5725421.0       0.00      0.00      0.00         1\n",
      "   5726101.0       0.00      0.00      0.00         1\n",
      "   5729842.0       0.00      0.00      0.00         1\n",
      "   5731006.0       0.00      0.00      0.00         1\n",
      "   5732890.0       0.00      0.00      0.00         1\n",
      "   5735774.0       0.00      0.00      0.00         1\n",
      "   5737628.0       0.00      0.00      0.00         1\n",
      "   5739084.0       0.00      0.00      0.00         1\n",
      "   5739131.0       0.00      0.00      0.00         1\n",
      "   5739313.0       0.00      0.00      0.00         1\n",
      "   5742733.0       0.00      0.00      0.00         1\n",
      "   5759402.0       0.00      0.00      0.00         1\n",
      "   5769615.0       0.00      0.00      0.00         1\n",
      "   5772223.0       0.00      0.00      0.00         1\n",
      "   5774501.0       0.00      0.00      0.00         1\n",
      "   5775252.0       0.00      0.00      0.00         1\n",
      "   5776897.0       0.00      0.00      0.00         1\n",
      "   5777400.0       0.00      0.00      0.00         1\n",
      "   5782093.0       0.00      0.00      0.00         1\n",
      "   5782259.0       0.00      0.00      0.00         1\n",
      "   5784027.0       0.00      0.00      0.00         1\n",
      "   5784505.0       0.00      0.00      0.00         1\n",
      "   5788114.0       0.00      0.00      0.00         1\n",
      "   5788546.0       0.00      0.00      0.00         1\n",
      "   5792399.0       0.00      0.00      0.00         1\n",
      "   5797126.0       0.00      0.00      0.00         1\n",
      "   5797780.0       0.00      0.00      0.00         1\n",
      "   5800485.0       0.00      0.00      0.00         1\n",
      "   5805967.0       0.00      0.00      0.00         1\n",
      "   5806296.0       0.00      0.00      0.00         1\n",
      "   5811559.0       0.00      0.00      0.00         1\n",
      "   5812090.0       0.00      0.00      0.00         1\n",
      "   5812930.0       0.00      0.00      0.00         1\n",
      "   5813968.0       0.00      0.00      0.00         1\n",
      "   5814516.0       0.00      0.00      0.00         1\n",
      "   5816122.0       0.00      0.00      0.00         1\n",
      "   5816279.0       0.00      0.00      0.00         1\n",
      "   5823354.0       0.00      0.00      0.00         1\n",
      "   5826384.0       0.00      0.00      0.00         1\n",
      "   5831780.0       0.00      0.00      0.00         1\n",
      "   5833810.0       0.00      0.00      0.00         1\n",
      "   5835104.0       0.00      0.00      0.00         1\n",
      "   5836985.0       0.00      0.00      0.00         1\n",
      "   5837467.0       0.00      0.00      0.00         1\n",
      "   5838112.0       0.00      0.00      0.00         1\n",
      "   5840113.0       0.00      0.00      0.00         1\n",
      "   5843117.0       0.00      0.00      0.00         1\n",
      "   5847711.0       0.00      0.00      0.00         1\n",
      "   5849684.0       0.00      0.00      0.00         1\n",
      "   5851321.0       0.00      0.00      0.00         1\n",
      "   5852759.0       0.00      0.00      0.00         1\n",
      "   5854294.0       0.00      0.00      0.00         1\n",
      "   5854432.0       0.00      0.00      0.00         1\n",
      "   5857267.0       0.00      0.00      0.00         1\n",
      "   5861467.0       0.00      0.00      0.00         1\n",
      "   5861770.0       0.00      0.00      0.00         1\n",
      "   5864346.0       0.00      0.00      0.00         1\n",
      "   5865812.0       0.00      0.00      0.00         1\n",
      "   5868973.0       0.00      0.00      0.00         1\n",
      "   5870623.0       0.00      0.00      0.00         1\n",
      "   5871739.0       0.00      0.00      0.00         1\n",
      "   5872812.0       0.00      0.00      0.00         1\n",
      "   5874941.0       0.00      0.00      0.00         1\n",
      "   5879323.0       0.00      0.00      0.00         1\n",
      "   5883903.0       0.00      0.00      0.00         1\n",
      "   5886950.0       0.00      0.00      0.00         1\n",
      "   5887490.0       0.00      0.00      0.00         1\n",
      "   5887819.0       0.00      0.00      0.00         1\n",
      "   5888620.0       0.00      0.00      0.00         1\n",
      "   5891252.0       0.00      0.00      0.00         1\n",
      "   5893954.0       0.00      0.00      0.00         1\n",
      "   5894510.0       0.00      0.00      0.00         1\n",
      "   5895511.0       0.00      0.00      0.00         1\n",
      "   5895716.0       0.00      0.00      0.00         1\n",
      "   5902041.0       0.00      0.00      0.00         1\n",
      "   5902126.0       0.00      0.00      0.00         1\n",
      "   5902304.0       0.00      0.00      0.00         1\n",
      "   5905562.0       0.00      0.00      0.00         1\n",
      "   5906691.0       0.00      0.00      0.00         1\n",
      "   5907998.0       0.00      0.00      0.00         1\n",
      "   5909348.0       0.00      0.00      0.00         1\n",
      "   5910852.0       0.00      0.00      0.00         1\n",
      "   5911102.0       0.00      0.00      0.00         1\n",
      "   5915452.0       0.00      0.00      0.00         1\n",
      "   5916973.0       0.00      0.00      0.00         1\n",
      "   5921587.0       0.00      0.00      0.00         1\n",
      "   5921926.0       0.00      0.00      0.00         1\n",
      "   5922422.0       0.00      0.00      0.00         1\n",
      "   5925923.0       0.00      0.00      0.00         1\n",
      "   5927932.0       0.00      0.00      0.00         1\n",
      "   5928252.0       0.00      0.00      0.00         1\n",
      "   5929278.0       0.00      0.00      0.00         1\n",
      "   5929767.0       0.00      0.00      0.00         1\n",
      "   5930517.0       0.00      0.00      0.00         1\n",
      "   5930665.0       0.00      0.00      0.00         1\n",
      "   5932132.0       0.00      0.00      0.00         1\n",
      "   5933534.0       0.00      0.00      0.00         1\n",
      "   5933967.0       0.00      0.00      0.00         1\n",
      "   5935432.0       0.00      0.00      0.00         1\n",
      "   5937342.0       0.00      0.00      0.00         1\n",
      "   5943318.0       0.00      0.00      0.00         1\n",
      "   5943580.0       0.00      0.00      0.00         1\n",
      "   5944631.0       0.00      0.00      0.00         1\n",
      "   5945144.0       0.00      0.00      0.00         1\n",
      "   5948765.0       0.00      0.00      0.00         1\n",
      "   5949292.0       0.00      0.00      0.00         1\n",
      "   5951917.0       0.00      0.00      0.00         1\n",
      "   5952829.0       0.00      0.00      0.00         1\n",
      "   5958094.0       0.00      0.00      0.00         1\n",
      "   5959334.0       0.00      0.00      0.00         1\n",
      "   5960864.0       0.00      0.00      0.00         1\n",
      "   5964614.0       0.00      0.00      0.00         1\n",
      "   5966767.0       0.00      0.00      0.00         1\n",
      "   5967292.0       0.00      0.00      0.00         1\n",
      "   5970934.0       0.00      0.00      0.00         1\n",
      "   5971035.0       0.00      0.00      0.00         1\n",
      "   5971091.0       0.00      0.00      0.00         1\n",
      "   5972130.0       0.00      0.00      0.00         1\n",
      "   5973626.0       0.00      0.00      0.00         1\n",
      "   5974765.0       0.00      0.00      0.00         1\n",
      "   5976148.0       0.00      0.00      0.00         1\n",
      "   5976995.0       0.00      0.00      0.00         1\n",
      "   5978011.0       0.00      0.00      0.00         1\n",
      "   5978636.0       0.00      0.00      0.00         1\n",
      "   5979537.0       0.00      0.00      0.00         1\n",
      "   5979666.0       0.00      0.00      0.00         1\n",
      "   5980941.0       0.00      0.00      0.00         1\n",
      "   5980981.0       0.00      0.00      0.00         1\n",
      "   5981370.0       0.00      0.00      0.00         1\n",
      "   5981888.0       0.00      0.00      0.00         1\n",
      "   5982193.0       0.00      0.00      0.00         1\n",
      "   5982858.0       0.00      0.00      0.00         1\n",
      "   5983374.0       0.00      0.00      0.00         1\n",
      "   5996739.0       0.00      0.00      0.00         1\n",
      "   5998097.0       0.00      0.00      0.00         1\n",
      "   5998168.0       0.00      0.00      0.00         1\n",
      "   5998930.0       0.00      0.00      0.00         1\n",
      "   5999109.0       0.00      0.00      0.00         1\n",
      "   5999485.0       0.00      0.00      0.00         1\n",
      "   5999503.0       0.00      0.00      0.00         1\n",
      "   5999504.0       0.00      0.00      0.00         1\n",
      "   5999527.0       0.00      0.00      0.00         1\n",
      "   5999618.0       0.00      0.00      0.00         1\n",
      "   5999626.0       0.00      0.00      0.00         1\n",
      "   5999629.0       0.00      0.00      0.00         1\n",
      "   5999639.0       0.00      0.00      0.00         1\n",
      "   5999651.0       0.00      0.00      0.00         1\n",
      "   5999656.0       0.00      0.00      0.00         1\n",
      "   5999657.0       0.00      0.00      0.00         1\n",
      "   5999703.0       0.00      0.00      0.00         1\n",
      "   5999712.0       0.00      0.00      0.00         1\n",
      "   5999716.0       0.00      0.00      0.00         1\n",
      "   5999722.0       0.00      0.00      0.00         1\n",
      "   5999727.0       0.00      0.00      0.00         1\n",
      "   5999735.0       0.00      0.00      0.00         1\n",
      "   5999745.0       0.00      0.00      0.00         1\n",
      "   5999748.0       0.00      0.00      0.00         1\n",
      "   5999750.0       0.00      0.00      0.00         1\n",
      "   5999752.0       0.00      0.00      0.00         1\n",
      "   5999756.0       0.00      0.00      0.00         1\n",
      "   5999758.0       0.00      0.00      0.00         1\n",
      "   5999764.0       0.00      0.00      0.00         1\n",
      "   5999768.0       0.00      0.00      0.00         2\n",
      "   5999773.0       0.00      0.00      0.00         1\n",
      "   5999777.0       0.00      0.00      0.00         1\n",
      "   5999781.0       0.00      0.00      0.00         1\n",
      "   5999783.0       0.00      0.00      0.00         2\n",
      "   5999788.0       0.00      0.00      0.00         1\n",
      "   5999789.0       0.00      0.00      0.00         1\n",
      "   5999793.0       0.00      0.00      0.00         1\n",
      "   5999794.0       0.00      0.00      0.00         1\n",
      "   5999957.0       0.00      0.00      0.00         1\n",
      "   5999969.0       0.00      0.00      0.00         1\n",
      "   5999971.0       0.00      0.00      0.00         2\n",
      "   6000197.0       0.00      0.00      0.00         1\n",
      "   6000285.0       0.00      0.00      0.00         1\n",
      "   6000314.0       0.00      0.00      0.00         1\n",
      "   6000367.0       0.00      0.00      0.00         1\n",
      "   6000381.0       0.00      0.00      0.00         1\n",
      "   6000407.0       0.00      0.00      0.00         1\n",
      "   6000412.0       0.00      0.00      0.00         1\n",
      "   6000421.0       0.00      0.00      0.00         1\n",
      "   6000443.0       0.00      0.00      0.00         1\n",
      "   6000464.0       0.00      0.00      0.00         1\n",
      "   6000800.0       0.00      0.00      0.00         1\n",
      "   6000814.0       0.00      0.00      0.00         1\n",
      "   6001027.0       0.00      0.00      0.00         1\n",
      "   6003425.0       0.00      0.00      0.00         1\n",
      "   6021731.0       0.00      0.00      0.00         1\n",
      "   6046585.0       0.00      0.00      0.00         1\n",
      "   6047531.0       0.00      0.00      0.00         1\n",
      "   6058338.0       0.00      0.00      0.00         1\n",
      "   6070175.0       0.00      0.00      0.00         1\n",
      "   6079555.0       0.00      0.00      0.00         1\n",
      "   6082173.0       0.00      0.00      0.00         1\n",
      "   6086115.0       0.00      0.00      0.00         1\n",
      "   6116053.0       0.00      0.00      0.00         1\n",
      "   6119877.0       0.00      0.00      0.00         1\n",
      "   6122440.0       0.00      0.00      0.00         1\n",
      "   6126814.0       0.00      0.00      0.00         1\n",
      "   6139717.0       0.00      0.00      0.00         1\n",
      "   6148115.0       0.00      0.00      0.00         1\n",
      "   6148819.0       0.00      0.00      0.00         1\n",
      "   6199727.0       0.00      0.00      0.00         1\n",
      "   6199963.0       0.00      0.00      0.00         1\n",
      "   6207878.0       0.00      0.00      0.00         1\n",
      "   6208668.0       0.00      0.00      0.00         1\n",
      "   6216954.0       0.00      0.00      0.00         1\n",
      "   6219879.0       0.00      0.00      0.00         1\n",
      "   6256938.0       0.00      0.00      0.00         1\n",
      "   6263942.0       0.00      0.00      0.00         1\n",
      "   6267328.0       0.00      0.00      0.00         1\n",
      "   6268206.0       0.00      0.00      0.00         1\n",
      "   6360123.0       0.00      0.00      0.00         1\n",
      "   6377473.0       0.00      0.00      0.00         1\n",
      "   6413032.0       0.00      0.00      0.00         1\n",
      "   6437191.0       0.00      0.00      0.00         1\n",
      "   6447209.0       0.00      0.00      0.00         1\n",
      "   6455107.0       0.00      0.00      0.00         1\n",
      "   6491333.0       0.00      0.00      0.00         1\n",
      "   6497894.0       0.00      0.00      0.00         1\n",
      "   6542400.0       0.00      0.00      0.00         1\n",
      "   6561128.0       0.00      0.00      0.00         1\n",
      "   6562555.0       0.00      0.00      0.00         1\n",
      "   6570310.0       0.00      0.00      0.00         1\n",
      "   6581426.0       0.00      0.00      0.00         1\n",
      "   6630612.0       0.00      0.00      0.00         1\n",
      "   6719963.0       0.00      0.00      0.00         1\n",
      "   6743635.0       0.00      0.00      0.00         1\n",
      "   6744500.0       0.00      0.00      0.00         1\n",
      "   6745686.0       0.00      0.00      0.00         1\n",
      "   6748842.0       0.00      0.00      0.00         1\n",
      "   6749707.0       0.00      0.00      0.00         1\n",
      "   6755418.0       0.00      0.00      0.00         1\n",
      "   6779764.0       0.00      0.00      0.00         1\n",
      "   6788970.0       0.00      0.00      0.00         1\n",
      "   6806406.0       0.00      0.00      0.00         1\n",
      "   6829737.0       0.00      0.00      0.00         1\n",
      "   6839510.0       0.00      0.00      0.00         1\n",
      "   6891647.0       0.00      0.00      0.00         1\n",
      "   6895844.0       0.00      0.00      0.00         1\n",
      "   6951034.0       0.00      0.00      0.00         1\n",
      "   6955212.0       0.00      0.00      0.00         1\n",
      "   6962865.0       0.00      0.00      0.00         1\n",
      "   6986611.0       0.00      0.00      0.00         1\n",
      "   7003519.0       0.00      0.00      0.00         1\n",
      "   7005487.0       0.00      0.00      0.00         1\n",
      "   7008898.0       0.00      0.00      0.00         1\n",
      "   7017299.0       0.00      0.00      0.00         1\n",
      "   7033699.0       0.00      0.00      0.00         1\n",
      "   7033955.0       0.00      0.00      0.00         1\n",
      "   7055821.0       0.00      0.00      0.00         1\n",
      "   7082270.0       0.00      0.00      0.00         1\n",
      "   7098282.0       0.00      0.00      0.00         1\n",
      "   7115382.0       0.00      0.00      0.00         1\n",
      "   7115716.0       0.00      0.00      0.00         1\n",
      "   7123133.0       0.00      0.00      0.00         1\n",
      "   7125650.0       0.00      0.00      0.00         1\n",
      "   7178713.0       0.00      0.00      0.00         1\n",
      "   7205039.0       0.00      0.00      0.00         1\n",
      "   7212680.0       0.00      0.00      0.00         1\n",
      "   7227716.0       0.00      0.00      0.00         1\n",
      "   7235252.0       0.00      0.00      0.00         1\n",
      "   7314304.0       0.00      0.00      0.00         1\n",
      "   7495036.0       0.00      0.00      0.00         1\n",
      "   7510838.0       0.00      0.00      0.00         1\n",
      "   7553752.0       0.00      0.00      0.00         1\n",
      "   7563996.0       0.00      0.00      0.00         1\n",
      "   7618230.0       0.00      0.00      0.00         1\n",
      "   7623700.0       0.00      0.00      0.00         1\n",
      "   7630353.0       0.00      0.00      0.00         1\n",
      "   7691312.0       0.00      0.00      0.00         1\n",
      "   7780658.0       0.00      0.00      0.00         1\n",
      "   7801096.0       0.00      0.00      0.00         1\n",
      "   7861710.0       0.00      0.00      0.00         1\n",
      "   7869145.0       0.00      0.00      0.00         1\n",
      "   7878409.0       0.00      0.00      0.00         1\n",
      "   7878560.0       0.00      0.00      0.00         1\n",
      "   7887861.0       0.00      0.00      0.00         1\n",
      "   7893289.0       0.00      0.00      0.00         1\n",
      "   7965790.0       0.00      0.00      0.00         1\n",
      "   7978593.0       0.00      0.00      0.00         1\n",
      "   7983470.0       0.00      0.00      0.00         1\n",
      "   8000089.0       0.00      0.00      0.00         1\n",
      "   8001414.0       0.00      0.00      0.00         1\n",
      "   8127795.0       0.00      0.00      0.00         1\n",
      "   8160253.0       0.00      0.00      0.00         1\n",
      "   8179978.0       0.00      0.00      0.00         1\n",
      "   8191525.0       0.00      0.00      0.00         1\n",
      "   8191975.0       0.00      0.00      0.00         1\n",
      "   8192541.0       0.00      0.00      0.00         1\n",
      "   8195931.0       0.00      0.00      0.00         1\n",
      "   8231322.0       0.00      0.00      0.00         1\n",
      "   8239870.0       0.00      0.00      0.00         1\n",
      "   8253609.0       0.00      0.00      0.00         1\n",
      "   8262001.0       0.00      0.00      0.00         1\n",
      "   8352285.0       0.00      0.00      0.00         1\n",
      "   8358904.0       0.00      0.00      0.00         1\n",
      "   8406123.0       0.00      0.00      0.00         1\n",
      "   8434946.0       0.00      0.00      0.00         1\n",
      "   8458122.0       0.00      0.00      0.00         1\n",
      "   8553976.0       0.00      0.00      0.00         1\n",
      "   8671278.0       0.00      0.00      0.00         1\n",
      "   8675127.0       0.00      0.00      0.00         1\n",
      "   8690299.0       0.00      0.00      0.00         1\n",
      "   8726389.0       0.00      0.00      0.00         1\n",
      "   8785119.0       0.00      0.00      0.00         1\n",
      "   8883459.0       0.00      0.00      0.00         1\n",
      "   8919359.0       0.00      0.00      0.00         1\n",
      "   8939463.0       0.00      0.00      0.00         1\n",
      "   8974760.0       0.00      0.00      0.00         1\n",
      "   8999948.0       0.00      0.00      0.00         1\n",
      "   9019230.0       0.00      0.00      0.00         1\n",
      "   9100324.0       0.00      0.00      0.00         1\n",
      "   9154556.0       0.00      0.00      0.00         1\n",
      "   9172235.0       0.00      0.00      0.00         1\n",
      "   9322587.0       0.00      0.00      0.00         1\n",
      "   9357316.0       0.00      0.00      0.00         1\n",
      "   9390912.0       0.00      0.00      0.00         1\n",
      "   9401384.0       0.00      0.00      0.00         1\n",
      "   9407428.0       0.00      0.00      0.00         1\n",
      "   9507579.0       0.00      0.00      0.00         1\n",
      "   9520003.0       0.00      0.00      0.00         1\n",
      "   9579623.0       0.00      0.00      0.00         1\n",
      "   9600842.0       0.00      0.00      0.00         1\n",
      "   9684750.0       0.00      0.00      0.00         1\n",
      "   9718170.0       0.00      0.00      0.00         1\n",
      "   9744143.0       0.00      0.00      0.00         1\n",
      "   9792215.0       0.00      0.00      0.00         1\n",
      "   9808125.0       0.00      0.00      0.00         1\n",
      "   9831129.0       0.00      0.00      0.00         1\n",
      "   9845879.0       0.00      0.00      0.00         1\n",
      "   9849804.0       0.00      0.00      0.00         1\n",
      "   9864981.0       0.00      0.00      0.00         1\n",
      "   9866158.0       0.00      0.00      0.00         1\n",
      "   9908239.0       0.00      0.00      0.00         1\n",
      "   9951382.0       0.00      0.00      0.00         1\n",
      "   9952111.0       0.00      0.00      0.00         1\n",
      "   9955413.0       0.00      0.00      0.00         1\n",
      "   9955693.0       0.00      0.00      0.00         1\n",
      "   9956096.0       0.00      0.00      0.00         1\n",
      "   9956584.0       0.00      0.00      0.00         1\n",
      "   9956998.0       0.00      0.00      0.00         1\n",
      "   9957547.0       0.00      0.00      0.00         1\n",
      "   9957757.0       0.00      0.00      0.00         1\n",
      "   9958930.0       0.00      0.00      0.00         1\n",
      "   9959300.0       0.00      0.00      0.00         1\n",
      "   9959515.0       0.00      0.00      0.00         1\n",
      "   9959577.0       0.00      0.00      0.00         1\n",
      "   9959618.0       0.00      0.00      0.00         1\n",
      "   9959663.0       0.00      0.00      0.00         2\n",
      "   9959754.0       0.00      0.00      0.00         1\n",
      "   9959798.0       0.00      0.00      0.00         1\n",
      "   9959858.0       0.00      0.00      0.00         1\n",
      "   9959859.0       0.00      0.00      0.00         1\n",
      "   9959887.0       0.00      0.00      0.00         1\n",
      "   9959921.0       0.00      0.00      0.00         1\n",
      "   9959937.0       0.00      0.00      0.00         1\n",
      "   9959957.0       0.00      0.00      0.00         1\n",
      "   9959981.0       0.00      0.00      0.00         1\n",
      "   9959984.0       0.00      0.00      0.00         1\n",
      "   9959986.0       0.00      0.00      0.00         1\n",
      "   9960004.0       0.00      0.00      0.00         1\n",
      "   9960016.0       0.00      0.00      0.00         1\n",
      "   9960080.0       0.00      0.00      0.00         1\n",
      "   9960085.0       0.00      0.00      0.00         1\n",
      "   9960149.0       0.00      0.00      0.00         1\n",
      "   9960171.0       0.00      0.00      0.00         1\n",
      "   9960189.0       0.00      0.00      0.00         1\n",
      "   9960200.0       0.00      0.00      0.00         1\n",
      "   9960206.0       0.00      0.00      0.00         1\n",
      "   9960366.0       0.00      0.00      0.00         1\n",
      "   9960379.0       0.00      0.00      0.00         1\n",
      "   9960539.0       0.00      0.00      0.00         1\n",
      "   9960582.0       0.00      0.00      0.00         1\n",
      "   9960616.0       0.00      0.00      0.00         1\n",
      "   9960668.0       0.00      0.00      0.00         1\n",
      "   9963084.0       0.00      0.00      0.00         1\n",
      "   9963269.0       0.00      0.00      0.00         1\n",
      "   9963553.0       0.00      0.00      0.00         1\n",
      "   9963715.0       0.00      0.00      0.00         1\n",
      "   9963925.0       0.00      0.00      0.00         1\n",
      "   9963989.0       0.00      0.00      0.00         1\n",
      "   9964047.0       0.00      0.00      0.00         1\n",
      "   9964049.0       0.00      0.00      0.00         1\n",
      "   9964089.0       0.00      0.00      0.00         1\n",
      "   9964108.0       0.00      0.00      0.00         1\n",
      "   9964383.0       0.00      0.00      0.00         1\n",
      "   9967518.0       0.00      0.00      0.00         1\n",
      "   9967673.0       0.00      0.00      0.00         1\n",
      "   9967951.0       0.00      0.00      0.00         1\n",
      "   9967975.0       0.00      0.00      0.00         1\n",
      "   9971608.0       0.00      0.00      0.00         1\n",
      "   9972106.0       0.00      0.00      0.00         1\n",
      "   9972130.0       0.00      0.00      0.00         1\n",
      "   9972138.0       0.00      0.00      0.00         1\n",
      "   9972291.0       0.00      0.00      0.00         1\n",
      "   9972883.0       0.00      0.00      0.00         1\n",
      "   9974274.0       0.00      0.00      0.00         1\n",
      "   9974276.0       0.00      0.00      0.00         1\n",
      "   9975847.0       0.00      0.00      0.00         1\n",
      "   9975928.0       0.00      0.00      0.00         1\n",
      "   9975948.0       0.00      0.00      0.00         1\n",
      "   9976007.0       0.00      0.00      0.00         1\n",
      "   9976070.0       0.00      0.00      0.00         1\n",
      "   9976422.0       0.00      0.00      0.00         1\n",
      "   9976749.0       0.00      0.00      0.00         1\n",
      "   9978643.0       0.00      0.00      0.00         1\n",
      "   9979183.0       0.00      0.00      0.00         1\n",
      "   9979661.0       0.00      0.00      0.00         1\n",
      "   9979667.0       0.00      0.00      0.00         1\n",
      "   9980021.0       0.00      0.00      0.00         1\n",
      "   9980136.0       0.00      0.00      0.00         1\n",
      "   9980191.0       0.00      0.00      0.00         1\n",
      "   9980575.0       0.00      0.00      0.00         1\n",
      "   9983271.0       0.00      0.00      0.00         1\n",
      "   9983405.0       0.00      0.00      0.00         1\n",
      "   9983506.0       0.00      0.00      0.00         1\n",
      "   9983624.0       0.00      0.00      0.00         1\n",
      "   9983787.0       0.00      0.00      0.00         1\n",
      "   9983863.0       0.00      0.00      0.00         1\n",
      "   9983886.0       0.00      0.00      0.00         1\n",
      "   9984036.0       0.00      0.00      0.00         1\n",
      "   9984086.0       0.00      0.00      0.00         1\n",
      "   9984144.0       0.00      0.00      0.00         1\n",
      "   9984303.0       0.00      0.00      0.00         1\n",
      "   9984599.0       0.00      0.00      0.00         1\n",
      "   9984613.0       0.00      0.00      0.00         1\n",
      "   9987755.0       0.00      0.00      0.00         1\n",
      "   9987886.0       0.00      0.00      0.00         1\n",
      "   9987984.0       0.00      0.00      0.00         1\n",
      "   9988411.0       0.00      0.00      0.00         1\n",
      "   9988477.0       0.00      0.00      0.00         1\n",
      "   9988578.0       0.00      0.00      0.00         1\n",
      "   9988631.0       0.00      0.00      0.00         1\n",
      "   9990405.0       0.00      0.00      0.00         1\n",
      "   9991898.0       0.00      0.00      0.00         1\n",
      "   9992222.0       0.00      0.00      0.00         1\n",
      "   9995991.0       0.00      0.00      0.00         1\n",
      "   9996337.0       0.00      0.00      0.00         1\n",
      "   9996412.0       0.00      0.00      0.00         1\n",
      "   9997749.0       0.00      0.00      0.00         1\n",
      "   9998327.0       0.00      0.00      0.00         1\n",
      "   9999499.0       0.00      0.00      0.00         1\n",
      "   9999519.0       0.00      0.00      0.00         1\n",
      "   9999688.0       0.00      0.00      0.00         1\n",
      "  10000000.0       0.12      0.07      0.09       221\n",
      "  10100000.0       0.00      0.01      0.00       111\n",
      "  10200000.0       0.16      0.01      0.02       760\n",
      "  10300000.0       0.00      0.00      0.00        31\n",
      "  10400000.0       0.00      0.00      0.00         5\n",
      "  10500000.0       0.00      0.00      0.00         4\n",
      "  10600000.0       0.00      0.00      0.00         1\n",
      "  10700000.0       0.00      0.00      0.00         1\n",
      "  11000000.0       0.00      0.00      0.00        11\n",
      "  11100000.0       0.00      0.00      0.00         2\n",
      "  11200000.0       0.00      0.00      0.00         1\n",
      "  11500000.0       0.00      0.00      0.00         0\n",
      "  11600000.0       0.00      0.00      0.00         1\n",
      "  11700000.0       0.00      0.00      0.00         1\n",
      "  11800000.0       0.00      0.00      0.00         1\n",
      "  11900000.0       0.00      0.00      0.00         2\n",
      "  12000000.0       0.00      0.00      0.00        28\n",
      "  12100000.0       0.00      0.00      0.00         3\n",
      "  12200000.0       0.00      0.00      0.00        17\n",
      "  12300000.0       0.00      0.00      0.00         2\n",
      "  12400000.0       0.00      0.00      0.00         1\n",
      "  12500000.0       0.00      0.00      0.00         1\n",
      "  12600000.0       0.00      0.00      0.00         1\n",
      "  13100000.0       0.00      0.00      0.00         2\n",
      "  13400000.0       0.00      0.00      0.00         2\n",
      "  13800000.0       0.00      0.00      0.00         1\n",
      "  14400000.0       0.00      0.00      0.00         3\n",
      "  14600000.0       0.00      0.00      0.00         1\n",
      "  14800000.0       0.00      0.00      0.00         1\n",
      "  14900000.0       0.00      0.00      0.00         2\n",
      "  15000000.0       0.00      0.00      0.00       100\n",
      "  15100000.0       0.00      0.00      0.00        49\n",
      "  15200000.0       0.00      0.00      0.00         1\n",
      "  15300000.0       0.00      0.00      0.00         2\n",
      "  15800000.0       0.00      0.00      0.00         1\n",
      "  16100000.0       0.00      0.00      0.00         1\n",
      "  16200000.0       0.00      0.00      0.00         0\n",
      "  16300000.0       0.00      0.00      0.00         1\n",
      "  16400000.0       0.00      0.00      0.00         2\n",
      "  16700000.0       0.00      0.00      0.00         1\n",
      "  16800000.0       0.00      0.00      0.00         1\n",
      "  17100000.0       0.00      0.00      0.00         1\n",
      "  17400000.0       0.00      0.00      0.00         3\n",
      "  17700000.0       0.00      0.00      0.00         1\n",
      "  17900000.0       0.00      0.00      0.00         2\n",
      "  18100000.0       0.20      1.00      0.33         2\n",
      "  18300000.0       0.00      0.00      0.00         2\n",
      "  18400000.0       0.00      0.00      0.00         2\n",
      "  18700000.0       0.00      0.00      0.00         2\n",
      "  18800000.0       0.00      0.00      0.00         1\n",
      "  19300000.0       0.00      0.00      0.00         1\n",
      "  19400000.0       0.00      0.00      0.00         1\n",
      "  19500000.0       0.00      0.00      0.00         1\n",
      "  19600000.0       0.00      0.00      0.00         0\n",
      "  19700000.0       0.00      0.00      0.00         3\n",
      "  19900000.0       0.00      0.00      0.00         1\n",
      "  20000000.0       0.00      0.00      0.00         1\n",
      "  20100000.0       0.00      0.00      0.00         2\n",
      "  20200000.0       0.00      0.00      0.00         2\n",
      "  20300000.0       0.00      0.00      0.00         2\n",
      "  20400000.0       0.00      0.00      0.00         4\n",
      "  20500000.0       0.00      0.00      0.00         1\n",
      "  20600000.0       0.00      0.00      0.00         2\n",
      "  20700000.0       0.00      0.00      0.00         2\n",
      "  20800000.0       0.00      0.00      0.00         4\n",
      "  20900000.0       0.00      0.00      0.00         1\n",
      "  21000000.0       0.00      0.00      0.00         2\n",
      "  21100000.0       0.00      0.00      0.00         2\n",
      "  21400000.0       0.00      0.00      0.00         1\n",
      "  21500000.0       0.00      0.00      0.00         3\n",
      "  21600000.0       0.00      0.00      0.00         3\n",
      "  22000000.0       0.00      0.00      0.00         3\n",
      "  22100000.0       0.00      0.00      0.00         1\n",
      "  22200000.0       0.00      0.00      0.00         3\n",
      "  22300000.0       0.00      0.00      0.00         0\n",
      "  22400000.0       0.00      0.00      0.00         3\n",
      "  22500000.0       0.00      0.00      0.00         2\n",
      "  22600000.0       0.00      0.00      0.00         0\n",
      "  22700000.0       0.00      0.00      0.00         6\n",
      "  22900000.0       0.00      0.00      0.00         2\n",
      "  23000000.0       0.00      0.00      0.00         1\n",
      "  23100000.0       0.00      0.00      0.00         2\n",
      "  23200000.0       0.00      0.00      0.00         4\n",
      "  23300000.0       0.00      0.00      0.00         3\n",
      "  23400000.0       0.00      0.00      0.00         2\n",
      "  23500000.0       0.00      0.00      0.00         2\n",
      "  23700000.0       0.00      0.00      0.00         1\n",
      "  23800000.0       0.00      0.00      0.00         3\n",
      "  23900000.0       0.00      0.00      0.00         1\n",
      "  24000000.0       0.00      0.00      0.00        21\n",
      "  24200000.0       0.00      0.00      0.00        23\n",
      "  24300000.0       0.00      0.00      0.00         2\n",
      "  24400000.0       0.00      0.00      0.00         2\n",
      "  24500000.0       0.00      0.00      0.00         1\n",
      "  24600000.0       0.00      0.00      0.00         3\n",
      "  24700000.0       0.00      0.00      0.00         2\n",
      "  24800000.0       0.00      0.00      0.00         4\n",
      "  24900000.0       0.00      0.00      0.00         2\n",
      "  25000000.0       0.00      0.00      0.00        22\n",
      "  25100000.0       0.00      0.00      0.00         6\n",
      "  25200000.0       0.00      0.00      0.00         2\n",
      "  25300000.0       0.00      0.00      0.00         4\n",
      "  25400000.0       0.00      0.00      0.00         2\n",
      "  25500000.0       0.00      0.00      0.00         1\n",
      "  25600000.0       0.00      0.00      0.00         1\n",
      "  25700000.0       0.00      0.00      0.00         4\n",
      "  25900000.0       0.00      0.00      0.00         3\n",
      "  26000000.0       0.00      0.00      0.00         1\n",
      "  26100000.0       0.00      0.00      0.00         1\n",
      "  26200000.0       0.00      0.00      0.00         1\n",
      "  26300000.0       0.00      0.00      0.00         1\n",
      "  26400000.0       0.00      0.00      0.00         3\n",
      "  26500000.0       0.14      0.25      0.18         4\n",
      "  26600000.0       0.00      0.00      0.00         1\n",
      "  26800000.0       0.00      0.00      0.00         3\n",
      "  26900000.0       0.00      0.00      0.00         2\n",
      "  27100000.0       0.00      0.00      0.00         4\n",
      "  27200000.0       0.00      0.00      0.00         4\n",
      "  27300000.0       0.00      0.00      0.00         1\n",
      "  27400000.0       0.00      0.00      0.00         2\n",
      "  27500000.0       0.00      0.00      0.00         2\n",
      "  27600000.0       0.00      0.00      0.00         5\n",
      "  27800000.0       0.00      0.00      0.00         5\n",
      "  27900000.0       0.00      1.00      0.00         2\n",
      "  28000000.0       0.00      0.00      0.00         3\n",
      "  28100000.0       0.00      0.00      0.00         1\n",
      "  28200000.0       0.00      0.00      0.00         2\n",
      "  28300000.0       0.00      0.00      0.00         3\n",
      "  28400000.0       0.00      0.00      0.00         5\n",
      "  28500000.0       0.00      0.00      0.00         5\n",
      "  28600000.0       0.00      0.00      0.00         4\n",
      "  28700000.0       0.00      0.00      0.00         3\n",
      "  28800000.0       0.00      0.00      0.00         8\n",
      "  28900000.0       0.00      0.00      0.00         4\n",
      "  29000000.0       0.00      0.00      0.00         8\n",
      "  29100000.0       0.00      0.00      0.00         9\n",
      "  29200000.0       0.00      0.00      0.00         8\n",
      "  29300000.0       0.00      0.00      0.00         8\n",
      "  29400000.0       0.00      0.00      0.00         7\n",
      "  29500000.0       0.00      0.00      0.00        17\n",
      "  29600000.0       0.00      0.00      0.00         7\n",
      "  29700000.0       0.00      0.00      0.00        15\n",
      "  29800000.0       0.00      0.00      0.00        21\n",
      "  29900000.0       0.00      0.00      0.00         8\n",
      "  30000000.0       0.00      0.00      0.00        32\n",
      "  30100000.0       0.00      0.00      0.00         4\n",
      "  30200000.0       0.00      0.00      0.00         1\n",
      "  30300000.0       0.00      0.00      0.00         6\n",
      "  30400000.0       0.00      0.00      0.00         1\n",
      "  30500000.0       0.00      0.00      0.00         1\n",
      "  30600000.0       0.00      0.00      0.00         2\n",
      "  30700000.0       0.00      0.00      0.00         1\n",
      "  30800000.0       0.00      0.00      0.00         1\n",
      "  30900000.0       0.00      0.00      0.00         2\n",
      "  31000000.0       0.00      0.00      0.00         2\n",
      "  31100000.0       0.00      0.00      0.00         1\n",
      "  31300000.0       0.00      0.00      0.00         1\n",
      "  31400000.0       0.00      0.00      0.00         2\n",
      "  31500000.0       0.00      0.00      0.00         1\n",
      "  31600000.0       0.00      0.00      0.00         1\n",
      "  31700000.0       0.00      0.00      0.00         1\n",
      "  31800000.0       0.00      0.00      0.00         2\n",
      "  32000000.0       0.00      0.00      0.00         3\n",
      "  32100000.0       0.00      0.00      0.00         1\n",
      "  32400000.0       0.00      0.00      0.00         2\n",
      "  32500000.0       0.00      0.00      0.00         1\n",
      "  32700000.0       0.00      0.00      0.00         1\n",
      "  33000000.0       0.00      0.00      0.00         1\n",
      "  33100000.0       0.00      0.00      0.00         2\n",
      "  33200000.0       0.00      0.00      0.00         1\n",
      "  33400000.0       0.00      0.00      0.00         1\n",
      "  33700000.0       0.00      0.00      0.00         1\n",
      "  33800000.0       0.00      0.00      0.00         1\n",
      "  34000000.0       1.00      0.50      0.67         2\n",
      "  34200000.0       0.00      0.00      0.00         2\n",
      "  34300000.0       0.00      0.00      0.00         2\n",
      "  34400000.0       0.00      0.00      0.00         2\n",
      "  34500000.0       0.00      0.00      0.00         2\n",
      "  34700000.0       0.00      0.00      0.00         1\n",
      "  34800000.0       0.00      0.00      0.00         1\n",
      "  34900000.0       0.00      0.00      0.00         1\n",
      "  35000000.0       0.00      0.00      0.00        15\n",
      "  35200000.0       0.00      0.00      0.00         2\n",
      "  35400000.0       0.00      0.00      0.00         1\n",
      "  35500000.0       0.00      0.00      0.00         2\n",
      "  35600000.0       0.00      0.00      0.00         4\n",
      "  35700000.0       0.00      0.00      0.00         1\n",
      "  35800000.0       0.00      0.00      0.00         5\n",
      "  36000000.0       0.00      0.00      0.00         1\n",
      "  36100000.0       0.00      0.00      0.00         1\n",
      "  36300000.0       0.00      0.00      0.00         1\n",
      "  36400000.0       0.00      0.00      0.00         1\n",
      "  36500000.0       0.00      0.00      0.00         2\n",
      "  36600000.0       0.00      0.00      0.00         1\n",
      "  36700000.0       0.00      0.00      0.00         1\n",
      "  36900000.0       0.00      0.00      0.00         2\n",
      "  37100000.0       0.00      0.00      0.00         2\n",
      "  37500000.0       0.00      0.00      0.00         1\n",
      "  37600000.0       0.00      0.00      0.00         2\n",
      "  37700000.0       0.00      0.00      0.00         2\n",
      "  37800000.0       0.00      0.00      0.00         1\n",
      "  37900000.0       0.00      0.00      0.00         1\n",
      "  38000000.0       0.00      0.00      0.00         1\n",
      "  38100000.0       0.00      0.00      0.00         1\n",
      "  38200000.0       0.00      0.00      0.00         1\n",
      "  38300000.0       0.00      0.00      0.00         1\n",
      "  38600000.0       0.00      0.00      0.00         1\n",
      "  38700000.0       0.00      0.00      0.00         1\n",
      "  38800000.0       0.00      0.00      0.00         1\n",
      "  38900000.0       0.00      0.00      0.00         2\n",
      "  39400000.0       0.00      0.00      0.00         1\n",
      "  39500000.0       0.00      0.00      0.00         1\n",
      "  39600000.0       0.00      0.00      0.00         3\n",
      "  39700000.0       0.00      0.00      0.00         2\n",
      "  39800000.0       0.00      0.00      0.00         1\n",
      "  39900000.0       0.00      0.00      0.00         2\n",
      "  40000000.0       0.00      0.00      0.00        42\n",
      "  40100000.0       0.00      0.00      0.00         6\n",
      "  40200000.0       0.00      0.00      0.00         1\n",
      "  40300000.0       0.00      0.00      0.00         2\n",
      "  40400000.0       0.00      0.00      0.00         1\n",
      "  40500000.0       0.00      0.00      0.00         1\n",
      "  40700000.0       0.00      0.00      0.00         1\n",
      "  40800000.0       0.00      0.00      0.00         2\n",
      "  41100000.0       0.00      0.00      0.00         4\n",
      "  41200000.0       0.00      0.00      0.00         1\n",
      "  41300000.0       0.00      0.00      0.00         4\n",
      "  41400000.0       0.00      0.00      0.00         1\n",
      "  41500000.0       0.00      0.00      0.00         2\n",
      "  41600000.0       0.00      0.00      0.00         1\n",
      "  41700000.0       0.00      0.00      0.00         1\n",
      "  41800000.0       0.00      0.00      0.00         2\n",
      "  41900000.0       0.00      0.00      0.00         2\n",
      "  42000000.0       0.00      0.00      0.00         2\n",
      "  42100000.0       0.00      0.00      0.00         1\n",
      "  42300000.0       0.00      0.00      0.00         1\n",
      "  42400000.0       0.00      0.00      0.00         1\n",
      "  42600000.0       0.00      0.00      0.00         2\n",
      "  42700000.0       0.00      0.00      0.00         1\n",
      "  43200000.0       0.00      0.00      0.00         1\n",
      "  43500000.0       0.00      0.00      0.00         2\n",
      "  43700000.0       0.00      0.00      0.00         2\n",
      "  43900000.0       0.00      0.00      0.00         1\n",
      "  44300000.0       0.00      0.00      0.00         0\n",
      "  44400000.0       0.00      0.00      0.00         1\n",
      "  44500000.0       0.00      0.00      0.00         1\n",
      "  44700000.0       0.00      0.00      0.00         0\n",
      "  44800000.0       0.00      0.00      0.00         1\n",
      "  44900000.0       0.00      0.00      0.00         1\n",
      "  45000000.0       0.00      0.00      0.00         0\n",
      "  45100000.0       0.00      0.00      0.00         1\n",
      "  45600000.0       0.00      0.00      0.00         1\n",
      "  45700000.0       0.00      0.00      0.00         2\n",
      "  45800000.0       0.00      0.00      0.00         1\n",
      "  45900000.0       0.00      0.00      0.00         8\n",
      "  46000000.0       0.00      0.00      0.00         9\n",
      "  46100000.0       0.00      0.00      0.00         2\n",
      "  46400000.0       0.00      0.00      0.00         1\n",
      "  46800000.0       0.00      0.00      0.00         2\n",
      "  46900000.0       0.00      0.00      0.00         1\n",
      "  47100000.0       0.00      0.00      0.00         1\n",
      "  47200000.0       0.00      0.00      0.00         1\n",
      "  47300000.0       0.00      0.00      0.00         1\n",
      "  47400000.0       0.00      0.00      0.00         2\n",
      "  47500000.0       0.00      0.00      0.00         2\n",
      "  47800000.0       0.00      0.00      0.00         2\n",
      "  47900000.0       0.00      0.00      0.00         1\n",
      "  48100000.0       0.00      0.00      0.00         1\n",
      "  48200000.0       0.00      0.00      0.00         1\n",
      "  48300000.0       0.00      0.00      0.00         1\n",
      "  48400000.0       0.00      0.00      0.00         1\n",
      "  48700000.0       0.00      0.00      0.00         1\n",
      "  49400000.0       0.00      0.00      0.00         1\n",
      "  49800000.0       0.00      0.00      0.00         3\n",
      "  49900000.0       0.00      0.00      0.00         1\n",
      "  50000000.0       0.00      0.00      0.00        28\n",
      "  50100000.0       0.00      0.00      0.00        16\n",
      "  50200000.0       0.00      0.00      0.00         3\n",
      "  50600000.0       0.00      0.00      0.00         2\n",
      "  50700000.0       0.00      0.00      0.00         0\n",
      "  50800000.0       0.00      0.00      0.00         1\n",
      "  51000000.0       0.00      0.00      0.00         1\n",
      "  51100000.0       0.00      0.00      0.00         7\n",
      "  51200000.0       0.00      0.00      0.00         1\n",
      "  51300000.0       0.00      0.00      0.00         1\n",
      "  51400000.0       0.00      0.00      0.00         1\n",
      "  51600000.0       0.00      0.00      0.00         1\n",
      "  51900000.0       0.00      0.00      0.00         2\n",
      "  52000000.0       0.00      0.00      0.00         3\n",
      "  52100000.0       0.00      0.00      0.00         1\n",
      "  52200000.0       0.00      0.00      0.00         1\n",
      "  52300000.0       0.00      0.00      0.00         1\n",
      "  52400000.0       0.00      0.00      0.00         4\n",
      "  52500000.0       0.00      0.00      0.00         7\n",
      "  52600000.0       0.00      0.00      0.00         1\n",
      "  52700000.0       0.00      0.00      0.00         3\n",
      "  52800000.0       0.00      0.00      0.00         3\n",
      "  52900000.0       0.00      0.00      0.00         1\n",
      "  53000000.0       0.00      0.00      0.00         6\n",
      "  53100000.0       0.00      0.00      0.00         8\n",
      "  53200000.0       0.00      0.00      0.00         7\n",
      "  53300000.0       0.00      0.00      0.00         1\n",
      "  53400000.0       0.00      0.00      0.00         5\n",
      "  53500000.0       0.00      0.00      0.00        12\n",
      "  53600000.0       0.00      0.00      0.00        10\n",
      "  53700000.0       0.00      0.00      0.00         6\n",
      "  53800000.0       0.00      0.00      0.00         9\n",
      "  53900000.0       0.00      0.00      0.00         3\n",
      "  54000000.0       0.00      0.00      0.00         4\n",
      "  54200000.0       0.00      0.00      0.00         3\n",
      "  54400000.0       0.00      0.00      0.00         3\n",
      "  54500000.0       0.00      0.00      0.00         5\n",
      "  54600000.0       0.00      0.00      0.00         2\n",
      "  54700000.0       0.00      0.00      0.00         1\n",
      "  54900000.0       0.00      0.00      0.00         1\n",
      "  55200000.0       0.00      0.00      0.00         1\n",
      "  55400000.0       0.00      0.00      0.00         1\n",
      "  55500000.0       0.00      0.00      0.00         1\n",
      "  55600000.0       0.00      0.00      0.00         1\n",
      "  55800000.0       0.00      0.00      0.00         1\n",
      "  55900000.0       0.00      0.00      0.00         3\n",
      "  56000000.0       0.00      0.00      0.00         1\n",
      "  56200000.0       0.00      0.00      0.00         1\n",
      "  56400000.0       0.00      0.00      0.00         0\n",
      "  56700000.0       0.00      0.00      0.00         1\n",
      "  56800000.0       0.00      0.00      0.00         1\n",
      "  57000000.0       0.00      0.00      0.00         3\n",
      "  57100000.0       0.00      0.00      0.00         2\n",
      "  57300000.0       0.00      0.00      0.00         1\n",
      "  57400000.0       0.00      0.00      0.00         1\n",
      "  57500000.0       0.00      0.00      0.00         2\n",
      "  57700000.0       0.00      0.00      0.00         2\n",
      "  57800000.0       0.00      0.00      0.00         1\n",
      "  57900000.0       0.00      0.00      0.00         3\n",
      "  58000000.0       0.00      0.00      0.00        30\n",
      "  58100000.0       0.00      0.00      0.00        46\n",
      "  58200000.0       0.00      0.00      0.00        64\n",
      "  58300000.0       0.00      0.00      0.00        79\n",
      "  58400000.0       0.00      0.00      0.00        96\n",
      "  58500000.0       0.00      0.00      0.00        82\n",
      "  58600000.0       0.00      0.00      0.00       112\n",
      "  58700000.0       0.00      0.00      0.00       102\n",
      "  58800000.0       0.00      0.00      0.00       116\n",
      "  58900000.0       0.00      0.00      0.00       112\n",
      "  59000000.0       0.00      0.00      0.00        51\n",
      "  59100000.0       0.00      0.00      0.00        10\n",
      "  59200000.0       0.00      0.00      0.00        14\n",
      "  59300000.0       0.00      0.00      0.00         8\n",
      "  59400000.0       0.00      0.00      0.00         2\n",
      "  59500000.0       0.00      0.00      0.00         3\n",
      "  59600000.0       0.00      0.00      0.00         5\n",
      "  59800000.0       0.00      0.00      0.00         4\n",
      "  59900000.0       0.00      0.00      0.00         2\n",
      "  60000000.0       0.00      0.00      0.00         2\n",
      "  60100000.0       0.00      0.00      0.00        15\n",
      "  60200000.0       0.00      0.00      0.00        21\n",
      "  60300000.0       0.00      0.00      0.00        31\n",
      "  60400000.0       0.00      0.00      0.00        61\n",
      "  60500000.0       0.00      0.00      0.00        72\n",
      "  60600000.0       0.00      0.00      0.00        77\n",
      "  60700000.0       0.00      0.00      0.00        99\n",
      "  60800000.0       1.00      0.03      0.06       133\n",
      "  60900000.0       0.00      0.00      0.00       139\n",
      "  61000000.0       0.00      0.00      0.00       174\n",
      "  61100000.0       0.00      0.00      0.00       172\n",
      "  61200000.0       0.00      0.00      0.00       191\n",
      "  61300000.0       0.00      0.00      0.00       237\n",
      "  61400000.0       0.00      0.00      0.00       234\n",
      "  61500000.0       0.00      0.00      0.00       240\n",
      "  61600000.0       0.00      0.00      0.00       209\n",
      "  61700000.0       0.00      0.00      0.00       207\n",
      "  61800000.0       0.00      0.00      0.00       190\n",
      "  61900000.0       0.00      0.00      0.00       222\n",
      "  62000000.0       0.00      0.00      0.00       235\n",
      "  62100000.0       0.00      0.00      0.00       217\n",
      "  62200000.0       0.00      0.00      0.00       206\n",
      "  62300000.0       0.00      0.00      0.00       205\n",
      "  62400000.0       0.00      0.00      0.00       153\n",
      "  62500000.0       0.00      0.00      0.00       161\n",
      "  62600000.0       0.00      0.00      0.00       117\n",
      "  62700000.0       0.00      0.00      0.00        98\n",
      "  62800000.0       0.00      0.00      0.00        90\n",
      "  62900000.0       0.00      0.00      0.00        95\n",
      "  63000000.0       0.00      0.00      0.00        84\n",
      "  63100000.0       0.00      0.00      0.00        83\n",
      "  63200000.0       0.00      0.00      0.00        53\n",
      "  63300000.0       0.00      0.00      0.00        69\n",
      "  63400000.0       0.00      0.00      0.00        41\n",
      "  63500000.0       0.00      0.00      0.00        44\n",
      "  63600000.0       0.00      0.00      0.00        41\n",
      "  63700000.0       0.00      0.00      0.00        35\n",
      "  63800000.0       0.00      0.00      0.00        28\n",
      "  63900000.0       0.00      0.00      0.00        39\n",
      "  64000000.0       0.00      0.00      0.00        31\n",
      "  64100000.0       0.00      0.00      0.00        15\n",
      "  64200000.0       0.00      0.00      0.00        15\n",
      "  64300000.0       0.00      0.00      0.00        22\n",
      "  64400000.0       0.00      0.00      0.00        13\n",
      "  64500000.0       0.00      0.00      0.00        21\n",
      "  64600000.0       0.00      0.00      0.00         5\n",
      "  64700000.0       0.00      0.00      0.00         9\n",
      "  64800000.0       0.00      0.00      0.00         9\n",
      "  64900000.0       0.00      0.00      0.00        11\n",
      "  65000000.0       0.00      0.00      0.00         5\n",
      "  65100000.0       0.00      0.00      0.00        16\n",
      "  65200000.0       0.00      0.00      0.00        12\n",
      "  65300000.0       0.00      0.00      0.00        14\n",
      "  65400000.0       0.00      0.00      0.00        15\n",
      "  65500000.0       0.00      0.00      0.00         6\n",
      "  65600000.0       0.00      0.00      0.00        13\n",
      "  65700000.0       0.00      0.00      0.00         2\n",
      "  65800000.0       0.00      0.00      0.00        10\n",
      "  65900000.0       0.00      0.00      0.00        10\n",
      "  66000000.0       0.00      0.00      0.00         6\n",
      "  66100000.0       0.00      0.00      0.00         6\n",
      "  66200000.0       0.00      0.00      0.00         6\n",
      "  66300000.0       0.00      0.00      0.00         5\n",
      "  66400000.0       0.00      0.00      0.00         5\n",
      "  66500000.0       0.00      0.00      0.00         5\n",
      "  66600000.0       0.00      0.00      0.00         7\n",
      "  66700000.0       0.00      0.00      0.00         7\n",
      "  66800000.0       0.00      0.00      0.00         2\n",
      "  66900000.0       0.00      0.00      0.00         7\n",
      "  67000000.0       0.00      0.00      0.00         3\n",
      "  67100000.0       0.00      0.00      0.00         3\n",
      "  67200000.0       0.00      0.00      0.00         2\n",
      "  67300000.0       0.00      0.00      0.00         2\n",
      "  67400000.0       0.00      0.00      0.00         8\n",
      "  67500000.0       0.00      0.00      0.00         1\n",
      "  67600000.0       0.00      0.00      0.00         2\n",
      "  67700000.0       0.00      0.00      0.00         4\n",
      "  67800000.0       0.00      0.00      0.00         2\n",
      "  67900000.0       0.00      0.00      0.00         6\n",
      "  68000000.0       0.00      0.00      0.00         7\n",
      "  68100000.0       0.00      0.00      0.00         5\n",
      "  68200000.0       0.00      0.00      0.00         1\n",
      "  68300000.0       0.00      0.00      0.00         4\n",
      "  68400000.0       0.00      0.00      0.00         2\n",
      "  68500000.0       0.00      0.00      0.00         3\n",
      "  68600000.0       0.00      0.00      0.00         1\n",
      "  68700000.0       0.00      0.00      0.00         2\n",
      "  68800000.0       0.00      0.00      0.00         3\n",
      "  68900000.0       0.00      0.00      0.00         1\n",
      "  69000000.0       0.00      0.00      0.00         7\n",
      "  69100000.0       0.00      0.00      0.00         2\n",
      "  69200000.0       0.00      0.00      0.00         2\n",
      "  69300000.0       0.00      0.00      0.00         1\n",
      "  69400000.0       0.00      0.00      0.00         2\n",
      "  69600000.0       0.00      0.00      0.00         5\n",
      "  69700000.0       0.00      0.00      0.00         1\n",
      "  69800000.0       0.00      0.00      0.00         2\n",
      "  69900000.0       0.00      0.00      0.00         1\n",
      "  70100000.0       0.00      0.00      0.00         4\n",
      "  70200000.0       0.00      0.00      0.00         2\n",
      "  70500000.0       0.00      0.00      0.00         0\n",
      "  70800000.0       0.00      0.00      0.00         1\n",
      "  70900000.0       0.00      0.00      0.00         2\n",
      "  71000000.0       0.00      0.00      0.00         3\n",
      "  71100000.0       0.00      0.00      0.00         1\n",
      "  71200000.0       0.00      0.00      0.00         2\n",
      "  71300000.0       0.00      0.00      0.00         3\n",
      "  71600000.0       0.00      0.00      0.00         1\n",
      "  71700000.0       0.00      0.00      0.00         2\n",
      "  71800000.0       0.00      0.00      0.00         4\n",
      "  71900000.0       0.00      0.00      0.00         1\n",
      "  72200000.0       0.00      0.00      0.00         2\n",
      "  72500000.0       0.00      0.00      0.00         2\n",
      "  72600000.0       0.00      0.00      0.00         1\n",
      "  72700000.0       0.00      0.00      0.00         1\n",
      "  72900000.0       0.00      0.00      0.00         1\n",
      "  73300000.0       0.00      0.00      0.00         1\n",
      "  73400000.0       0.00      0.00      0.00         1\n",
      "  73900000.0       0.00      0.00      0.00         2\n",
      "  74000000.0       0.00      0.00      0.00         1\n",
      "  75100000.0       0.00      0.00      0.00         1\n",
      "  77600000.0       0.00      0.00      0.00         1\n",
      "  77900000.0       0.00      0.00      0.00         1\n",
      "  79000000.0       0.00      0.00      0.00         1\n",
      "  79500000.0       0.00      0.00      0.00         1\n",
      "  79700000.0       0.00      0.00      0.00         1\n",
      "  80300000.0       0.00      0.00      0.00         1\n",
      "  80500000.0       0.00      0.00      0.00         1\n",
      "  80700000.0       0.00      0.00      0.00         1\n",
      "  81000000.0       0.00      0.00      0.00         0\n",
      "  81100000.0       0.00      0.00      0.00         1\n",
      "  81200000.0       0.00      0.00      0.00         1\n",
      "  81300000.0       0.00      0.00      0.00         1\n",
      "  81700000.0       0.00      0.00      0.00         2\n",
      "  81800000.0       0.00      0.00      0.00         1\n",
      "  82000000.0       0.00      0.00      0.00         2\n",
      "  82600000.0       0.00      0.00      0.00         1\n",
      "  82700000.0       0.00      0.00      0.00         1\n",
      "  83000000.0       0.00      0.00      0.00         1\n",
      "  83300000.0       0.00      0.00      0.00         1\n",
      "  83700000.0       0.00      0.00      0.00         2\n",
      "  84100000.0       0.00      0.00      0.00         1\n",
      "  84500000.0       1.00      0.50      0.67         2\n",
      "  84600000.0       0.00      0.00      0.00         0\n",
      "  85000000.0       0.00      0.00      0.00         1\n",
      "  85400000.0       0.00      0.00      0.00         0\n",
      "  85500000.0       0.00      0.00      0.00         1\n",
      "  86900000.0       0.00      0.00      0.00         1\n",
      "  87200000.0       0.00      0.00      0.00         1\n",
      "  88600000.0       0.00      0.00      0.00         1\n",
      "  89400000.0       0.00      0.00      0.00         1\n",
      "  90600000.0       0.00      0.00      0.00         1\n",
      "  91300000.0       0.00      0.00      0.00         2\n",
      "  91400000.0       0.00      0.00      0.00         1\n",
      "  93100000.0       0.00      0.00      0.00         1\n",
      "  94300000.0       0.00      0.00      0.00         1\n",
      "  95200000.0       0.00      0.00      0.00         1\n",
      "  95900000.0       0.00      0.00      0.00         1\n",
      "  98800000.0       0.00      0.00      0.00         1\n",
      "  99300000.0       0.00      0.00      0.00         0\n",
      "  99900000.0       0.00      0.00      0.00         1\n",
      " 104000000.0       0.67      0.67      0.67         3\n",
      " 105000000.0       0.00      0.00      0.00         1\n",
      " 106000000.0       0.00      0.00      0.00         2\n",
      " 110000000.0       0.00      0.00      0.00         1\n",
      " 111000000.0       0.33      1.00      0.50         1\n",
      " 112000000.0       0.00      0.00      0.00         3\n",
      " 113000000.0       0.00      0.00      0.00         1\n",
      " 114000000.0       0.50      0.50      0.50         2\n",
      " 115000000.0       0.00      0.00      0.00         1\n",
      " 116000000.0       0.00      0.00      0.00         4\n",
      " 117000000.0       0.00      0.00      0.00         3\n",
      " 118000000.0       0.00      0.00      0.00         7\n",
      " 119000000.0       0.00      0.00      0.00         6\n",
      " 120000000.0       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.84     61551\n",
      "   macro avg       0.00      0.00      0.00     61551\n",
      "weighted avg       0.85      0.84      0.84     61551\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4JndCumHD6Sk",
    "outputId": "ad5e7195-ade7-47da-ff13-f176015caea2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8401975597472016\n"
     ]
    }
   ],
   "source": [
    "pr=precision_score(y_test,y_pred, average='micro')\n",
    "print(\"Precision:\",pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ughz0jSdExNf"
   },
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "qYcB9vTJE8p8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OmOBMREFFJMO",
    "outputId": "40a0469c-6a80-4b48-f64b-e0b6e8b24bc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Flow ID        Src IP  Src Port        Dst IP  Dst Port  \\\n",
      "0       1.921683e+29  1.921683e+09     38694  2.001752e+09      4444   \n",
      "1       1.921683e+29  1.921683e+09     38693  2.001752e+09      4444   \n",
      "2       1.921683e+29  2.001752e+09     33747  1.921683e+09      3632   \n",
      "3       1.921683e+29  2.001752e+09     38745  1.921683e+09      8180   \n",
      "4       1.921683e+29  2.001752e+09     37217  1.921683e+09      8180   \n",
      "...              ...           ...       ...           ...       ...   \n",
      "205162  1.851272e+29  1.921682e+10     36100  1.851272e+09       443   \n",
      "205163  1.921682e+28  1.921682e+10     53032  1.921682e+08        53   \n",
      "205164  1.921682e+28  1.921682e+10     39285  1.921682e+08        53   \n",
      "205165  1.921682e+28  1.921682e+10     49895  1.921682e+08        53   \n",
      "205166  1.921682e+28  1.921682e+10     33786  1.921682e+08        53   \n",
      "\n",
      "        Protocol     Timestamp  Flow Duration  Tot Fwd Pkts  Tot Bwd Pkts  \\\n",
      "0              6  1.012021e+09         269709             4             5   \n",
      "1              6  1.012021e+09         268599             2             3   \n",
      "2              6  1.012021e+09          22194             5             5   \n",
      "3              6  1.012020e+09           9556             4             4   \n",
      "4              6  1.012020e+09           8782             4             4   \n",
      "...          ...           ...            ...           ...           ...   \n",
      "205162         6  5.220202e+09           1895             0             2   \n",
      "205163        17  5.220202e+09           3842             1             3   \n",
      "205164        17  5.220202e+09           3731             1             3   \n",
      "205165        17  5.220202e+09          20591             0             2   \n",
      "205166        17  5.220202e+09           3039             1             3   \n",
      "\n",
      "        ...  Fwd Seg Size Min  Active Mean  Active Std  Active Max  \\\n",
      "0       ...                 0          0.0         0.0         0.0   \n",
      "1       ...                 0          0.0         0.0         0.0   \n",
      "2       ...                 0          0.0         0.0         0.0   \n",
      "3       ...                 0          0.0         0.0         0.0   \n",
      "4       ...                 0          0.0         0.0         0.0   \n",
      "...     ...               ...          ...         ...         ...   \n",
      "205162  ...                 0          0.0         0.0         0.0   \n",
      "205163  ...                 0          0.0         0.0         0.0   \n",
      "205164  ...                 0          0.0         0.0         0.0   \n",
      "205165  ...                 0          0.0         0.0         0.0   \n",
      "205166  ...                 0          0.0         0.0         0.0   \n",
      "\n",
      "        Active Min  Idle Mean  Idle Std  Idle Max  Idle Min   Label  \n",
      "0              0.0        0.0       0.0       0.0       0.0     U2R  \n",
      "1              0.0        0.0       0.0       0.0       0.0     U2R  \n",
      "2              0.0        0.0       0.0       0.0       0.0     U2R  \n",
      "3              0.0        0.0       0.0       0.0       0.0     BFA  \n",
      "4              0.0        0.0       0.0       0.0       0.0     BFA  \n",
      "...            ...        ...       ...       ...       ...     ...  \n",
      "205162         0.0        0.0       0.0       0.0       0.0  Normal  \n",
      "205163         0.0        0.0       0.0       0.0       0.0  Normal  \n",
      "205164         0.0        0.0       0.0       0.0       0.0  Normal  \n",
      "205165         0.0        0.0       0.0       0.0       0.0  Normal  \n",
      "205166         0.0        0.0       0.0       0.0       0.0  Normal  \n",
      "\n",
      "[205167 rows x 84 columns]\n"
     ]
    }
   ],
   "source": [
    "#import the dataset\n",
    "df= pd.concat(map(pd.read_csv, ['metasploitable-2.csv', 'Normal_data.csv']), ignore_index=True)\n",
    "df[\"Src IP\"] = [float(str(i).replace(\".\", \"\")) for i in df[\"Src IP\"]]\n",
    "df[\"Dst IP\"] = [float(str(i).replace(\".\", \"\")) for i in df[\"Dst IP\"]]\n",
    "df[\"Flow ID\"] = [float(str(i).replace(\".\", \"\").replace(\"-\", \"\")) for i in df[\"Flow ID\"]]\n",
    "df[\"Timestamp\"] = [float(str(i).replace(\"/\", \"\").replace(\":\", \"\").replace(\" \",\"\").replace(\"PM\",\"\")) for i in df[\"Timestamp\"]]\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "EAE8gSUWFS79"
   },
   "outputs": [],
   "source": [
    "X = df.drop('Label', axis=1)\n",
    "y = df['Label'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "vDPYTstlFTgH"
   },
   "outputs": [],
   "source": [
    "#Split the training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "YEWqZr3vFTqM"
   },
   "outputs": [],
   "source": [
    "#feature Scaling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 79
    },
    "id": "D_7nHnJBF9Rs",
    "outputId": "4898c5a7-ed0a-4d45-a2c2-b39987cb1ed6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;KNeighborsClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">?<span>Documentation for KNeighborsClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>KNeighborsClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here we train the KNN algorithm to make predictions with it\n",
    "\n",
    "KNN = KNeighborsClassifier(n_neighbors=5)\n",
    "KNN.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "3-k43CKvF_PC"
   },
   "outputs": [],
   "source": [
    "#make predictions on the test data\n",
    "y_pred = KNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gJFXDKqiGDhU",
    "outputId": "95f06e32-cad4-4dad-8318-9b710215f0f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   54     0     0     0     0     0]\n",
      " [    0 14630     0     2     1     0]\n",
      " [    0     0   222     0     3     0]\n",
      " [    0     2     0 13650     1     0]\n",
      " [    0     0     0     0 12464     0]\n",
      " [    0     0     0     2     2     1]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "er66fXNpGD9d",
    "outputId": "dcae79c6-8f0f-49df-953e-43876dcaaab3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BFA       1.00      1.00      1.00        54\n",
      "        DDoS       1.00      1.00      1.00     14633\n",
      "         DoS       1.00      0.99      0.99       225\n",
      "      Normal       1.00      1.00      1.00     13653\n",
      "       Probe       1.00      1.00      1.00     12464\n",
      "         U2R       1.00      0.20      0.33         5\n",
      "\n",
      "    accuracy                           1.00     41034\n",
      "   macro avg       1.00      0.86      0.89     41034\n",
      "weighted avg       1.00      1.00      1.00     41034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_SLCYZ4YGIsp"
   },
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "6epUoDlNGdJw"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6q9qOs2ZGL78",
    "outputId": "b24eccc3-bfc4-4f1d-aeaf-893c75aa3e80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Flow ID        Src IP  Src Port        Dst IP  Dst Port  \\\n",
      "0       1.921683e+29  1.921683e+09     38694  2.001752e+09      4444   \n",
      "1       1.921683e+29  1.921683e+09     38693  2.001752e+09      4444   \n",
      "2       1.921683e+29  2.001752e+09     33747  1.921683e+09      3632   \n",
      "3       1.921683e+29  2.001752e+09     38745  1.921683e+09      8180   \n",
      "4       1.921683e+29  2.001752e+09     37217  1.921683e+09      8180   \n",
      "...              ...           ...       ...           ...       ...   \n",
      "205162  1.851272e+29  1.921682e+10     36100  1.851272e+09       443   \n",
      "205163  1.921682e+28  1.921682e+10     53032  1.921682e+08        53   \n",
      "205164  1.921682e+28  1.921682e+10     39285  1.921682e+08        53   \n",
      "205165  1.921682e+28  1.921682e+10     49895  1.921682e+08        53   \n",
      "205166  1.921682e+28  1.921682e+10     33786  1.921682e+08        53   \n",
      "\n",
      "        Protocol     Timestamp  Flow Duration  Tot Fwd Pkts  Tot Bwd Pkts  \\\n",
      "0              6  1.012021e+09         269709             4             5   \n",
      "1              6  1.012021e+09         268599             2             3   \n",
      "2              6  1.012021e+09          22194             5             5   \n",
      "3              6  1.012020e+09           9556             4             4   \n",
      "4              6  1.012020e+09           8782             4             4   \n",
      "...          ...           ...            ...           ...           ...   \n",
      "205162         6  5.220202e+09           1895             0             2   \n",
      "205163        17  5.220202e+09           3842             1             3   \n",
      "205164        17  5.220202e+09           3731             1             3   \n",
      "205165        17  5.220202e+09          20591             0             2   \n",
      "205166        17  5.220202e+09           3039             1             3   \n",
      "\n",
      "        ...  Fwd Seg Size Min  Active Mean  Active Std  Active Max  \\\n",
      "0       ...                 0          0.0         0.0         0.0   \n",
      "1       ...                 0          0.0         0.0         0.0   \n",
      "2       ...                 0          0.0         0.0         0.0   \n",
      "3       ...                 0          0.0         0.0         0.0   \n",
      "4       ...                 0          0.0         0.0         0.0   \n",
      "...     ...               ...          ...         ...         ...   \n",
      "205162  ...                 0          0.0         0.0         0.0   \n",
      "205163  ...                 0          0.0         0.0         0.0   \n",
      "205164  ...                 0          0.0         0.0         0.0   \n",
      "205165  ...                 0          0.0         0.0         0.0   \n",
      "205166  ...                 0          0.0         0.0         0.0   \n",
      "\n",
      "        Active Min  Idle Mean  Idle Std  Idle Max  Idle Min   Label  \n",
      "0              0.0        0.0       0.0       0.0       0.0     U2R  \n",
      "1              0.0        0.0       0.0       0.0       0.0     U2R  \n",
      "2              0.0        0.0       0.0       0.0       0.0     U2R  \n",
      "3              0.0        0.0       0.0       0.0       0.0     BFA  \n",
      "4              0.0        0.0       0.0       0.0       0.0     BFA  \n",
      "...            ...        ...       ...       ...       ...     ...  \n",
      "205162         0.0        0.0       0.0       0.0       0.0  Normal  \n",
      "205163         0.0        0.0       0.0       0.0       0.0  Normal  \n",
      "205164         0.0        0.0       0.0       0.0       0.0  Normal  \n",
      "205165         0.0        0.0       0.0       0.0       0.0  Normal  \n",
      "205166         0.0        0.0       0.0       0.0       0.0  Normal  \n",
      "\n",
      "[205167 rows x 84 columns]\n"
     ]
    }
   ],
   "source": [
    "#import the dataset\n",
    "df = pd.concat(map(pd.read_csv, ['metasploitable-2.csv', 'Normal_data.csv']), ignore_index=True)\n",
    "df[\"Src IP\"] = [float(str(i).replace(\".\", \"\")) for i in df[\"Src IP\"]]\n",
    "df[\"Dst IP\"] = [float(str(i).replace(\".\", \"\")) for i in df[\"Dst IP\"]]\n",
    "df[\"Flow ID\"] = [float(str(i).replace(\".\", \"\").replace(\"-\", \"\")) for i in df[\"Flow ID\"]]\n",
    "df[\"Timestamp\"] = [float(str(i).replace(\"/\", \"\").replace(\":\", \"\").replace(\" \",\"\").replace(\"PM\",\"\")) for i in df[\"Timestamp\"]]\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "oE7vhhJIGkoj"
   },
   "outputs": [],
   "source": [
    "#here we are preprocessing\n",
    "X = df.drop('Label',axis=1)\n",
    "y = df['Label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "uAg9n0cxGpkB"
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_Train, X_Test, y_Train, y_Test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "YWOsg_WCGpxE"
   },
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "X_Train = StandardScaler().fit_transform(X_Train)\n",
    "X_Test = StandardScaler().fit_transform(X_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 79
    },
    "id": "E0fDZxGSGp8q",
    "outputId": "1692bc1f-f5fb-4a4f-c47d-95beb05b2fed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-5 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-5 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-5 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-5 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-5 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, n_estimators=200, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, n_estimators=200, random_state=0)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=200, random_state=0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the classifier into the Training set\n",
    "RF = RandomForestClassifier(n_estimators = 200, criterion = 'entropy', random_state = 0)\n",
    "RF.fit(X_Train,y_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "wVBmSYh2HHM1"
   },
   "outputs": [],
   "source": [
    "# Predicting the test set results\n",
    "y_Pred = RF.predict(X_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "23TEqyJJHJme",
    "outputId": "a91a5847-fc7e-484a-fcc4-bdde0d5c3cf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   78     1     0     1     0     0]\n",
      " [    0 18237     0    16     0     0]\n",
      " [    0     0   233    56     7     0]\n",
      " [    0     0     0 17236     0     0]\n",
      " [    0     0     0   719 14706     0]\n",
      " [    0     0     0     0     0     2]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_Test, y_Pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A88_B6LnHIAF",
    "outputId": "38965cd9-dd86-4301-ee29-f1bfa0b6c6a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BFA       1.00      0.97      0.99        80\n",
      "        DDoS       1.00      1.00      1.00     18253\n",
      "         DoS       1.00      0.79      0.88       296\n",
      "      Normal       0.96      1.00      0.98     17236\n",
      "       Probe       1.00      0.95      0.98     15425\n",
      "         U2R       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.98     51292\n",
      "   macro avg       0.99      0.95      0.97     51292\n",
      "weighted avg       0.99      0.98      0.98     51292\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_Test, y_Pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGupt9ifHYT2"
   },
   "source": [
    "# DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "HguHz2N9HcY3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "69t22O0gHksb",
    "outputId": "38351be9-b4e8-446f-df57-b1a474825ea1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Flow ID        Src IP  Src Port        Dst IP  Dst Port  \\\n",
      "0       1.921683e+29  1.921683e+09     38694  2.001752e+09      4444   \n",
      "1       1.921683e+29  1.921683e+09     38693  2.001752e+09      4444   \n",
      "2       1.921683e+29  2.001752e+09     33747  1.921683e+09      3632   \n",
      "3       1.921683e+29  2.001752e+09     38745  1.921683e+09      8180   \n",
      "4       1.921683e+29  2.001752e+09     37217  1.921683e+09      8180   \n",
      "...              ...           ...       ...           ...       ...   \n",
      "205162  1.851272e+29  1.921682e+10     36100  1.851272e+09       443   \n",
      "205163  1.921682e+28  1.921682e+10     53032  1.921682e+08        53   \n",
      "205164  1.921682e+28  1.921682e+10     39285  1.921682e+08        53   \n",
      "205165  1.921682e+28  1.921682e+10     49895  1.921682e+08        53   \n",
      "205166  1.921682e+28  1.921682e+10     33786  1.921682e+08        53   \n",
      "\n",
      "        Protocol     Timestamp  Flow Duration  Tot Fwd Pkts  Tot Bwd Pkts  \\\n",
      "0              6  1.012021e+09         269709             4             5   \n",
      "1              6  1.012021e+09         268599             2             3   \n",
      "2              6  1.012021e+09          22194             5             5   \n",
      "3              6  1.012020e+09           9556             4             4   \n",
      "4              6  1.012020e+09           8782             4             4   \n",
      "...          ...           ...            ...           ...           ...   \n",
      "205162         6  5.220202e+09           1895             0             2   \n",
      "205163        17  5.220202e+09           3842             1             3   \n",
      "205164        17  5.220202e+09           3731             1             3   \n",
      "205165        17  5.220202e+09          20591             0             2   \n",
      "205166        17  5.220202e+09           3039             1             3   \n",
      "\n",
      "        ...  Fwd Seg Size Min  Active Mean  Active Std  Active Max  \\\n",
      "0       ...                 0          0.0         0.0         0.0   \n",
      "1       ...                 0          0.0         0.0         0.0   \n",
      "2       ...                 0          0.0         0.0         0.0   \n",
      "3       ...                 0          0.0         0.0         0.0   \n",
      "4       ...                 0          0.0         0.0         0.0   \n",
      "...     ...               ...          ...         ...         ...   \n",
      "205162  ...                 0          0.0         0.0         0.0   \n",
      "205163  ...                 0          0.0         0.0         0.0   \n",
      "205164  ...                 0          0.0         0.0         0.0   \n",
      "205165  ...                 0          0.0         0.0         0.0   \n",
      "205166  ...                 0          0.0         0.0         0.0   \n",
      "\n",
      "        Active Min  Idle Mean  Idle Std  Idle Max  Idle Min   Label  \n",
      "0              0.0        0.0       0.0       0.0       0.0     U2R  \n",
      "1              0.0        0.0       0.0       0.0       0.0     U2R  \n",
      "2              0.0        0.0       0.0       0.0       0.0     U2R  \n",
      "3              0.0        0.0       0.0       0.0       0.0     BFA  \n",
      "4              0.0        0.0       0.0       0.0       0.0     BFA  \n",
      "...            ...        ...       ...       ...       ...     ...  \n",
      "205162         0.0        0.0       0.0       0.0       0.0  Normal  \n",
      "205163         0.0        0.0       0.0       0.0       0.0  Normal  \n",
      "205164         0.0        0.0       0.0       0.0       0.0  Normal  \n",
      "205165         0.0        0.0       0.0       0.0       0.0  Normal  \n",
      "205166         0.0        0.0       0.0       0.0       0.0  Normal  \n",
      "\n",
      "[205167 rows x 84 columns]\n"
     ]
    }
   ],
   "source": [
    "#import the dataset\n",
    "df = pd.concat(map(pd.read_csv,['metasploitable-2.csv','Normal_data.csv']), ignore_index=True)\n",
    "df[\"Src IP\"] = [float(str(i).replace(\".\", \"\")) for i in df[\"Src IP\"]]\n",
    "df[\"Dst IP\"] = [float(str(i).replace(\".\", \"\")) for i in df[\"Dst IP\"]]\n",
    "df[\"Flow ID\"] = [float(str(i).replace(\".\", \"\").replace(\"-\", \"\")) for i in df[\"Flow ID\"]]\n",
    "df[\"Timestamp\"] = [float(str(i).replace(\"/\", \"\").replace(\":\", \"\").replace(\" \",\"\").replace(\"PM\",\"\")) for i in df[\"Timestamp\"]]\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "10PCgU1IJcFi"
   },
   "outputs": [],
   "source": [
    "#here we are preprocessing\n",
    "X = df.drop('Label', axis =1)\n",
    "y = df['Label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "RSNB4e6nJrEJ"
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_Train, X_Test, y_Train, y_Test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PHI4jhl8KVjn"
   },
   "source": [
    "# Stack Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HT-LuaQqKzV-",
    "outputId": "62b19304-c704-4ff6-f010-9063bb56a79a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Training set:\n",
      "Accuracy: 0.6571428571428571\n",
      "F1 score: 0.6058309037900874\n",
      "Precision: 0.6571428571428571\n",
      "\n",
      "Model performance for Test set:\n",
      "Accuracy: 0.5666666666666667\n",
      "F1 score: 0.4871202396234489\n",
      "Precision: 0.5666666666666667\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 3 13]\n",
      " [ 0 14]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.19      0.32        16\n",
      "           1       0.52      1.00      0.68        14\n",
      "\n",
      "    accuracy                           0.57        30\n",
      "   macro avg       0.76      0.59      0.50        30\n",
      "weighted avg       0.78      0.57      0.49        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Example Dataset: Replace this with your dataset\n",
    "# X, y = df.drop('target', axis=1), df['target']  # Replace 'target' with your actual label column\n",
    "X = np.random.rand(100, 5)  # Dummy features\n",
    "y = np.random.randint(0, 2, size=100)  # Dummy binary labels\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define individual models\n",
    "svm = SVC(probability=True, random_state=0)\n",
    "nb = GaussianNB()\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Create list of estimators\n",
    "estimator_list = [\n",
    "    ('SVM', svm),\n",
    "    ('NB', nb),\n",
    "    ('KNN', knn)\n",
    "]\n",
    "\n",
    "# Build and fit stack model\n",
    "stack_model = StackingClassifier(\n",
    "    estimators=estimator_list, final_estimator=LogisticRegression()\n",
    ")\n",
    "stack_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = stack_model.predict(X_train)\n",
    "y_test_pred = stack_model.predict(X_test)\n",
    "\n",
    "# Training set model performance\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
    "train_pr = precision_score(y_train, y_train_pred, average='micro')\n",
    "\n",
    "print('Model performance for Training set:')\n",
    "print('Accuracy: %s' % train_acc)\n",
    "print('F1 score: %s' % train_f1)\n",
    "print('Precision: %s' % train_pr)\n",
    "\n",
    "# Test set model performance\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "test_pr = precision_score(y_test, y_test_pred, average='micro')\n",
    "\n",
    "print('\\nModel performance for Test set:')\n",
    "print('Accuracy: %s' % test_acc)\n",
    "print('F1 score: %s' % test_f1)\n",
    "print('Precision: %s' % test_pr)\n",
    "\n",
    "# Confusion Matrix and Classification Report\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "print('\\nConfusion Matrix:')\n",
    "print(cm)\n",
    "\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_test_pred))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
